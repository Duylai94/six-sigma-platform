# PYTHON FOR SIX SIGMA - OPTIMIZED 10-DAY LEARNING SCHEDULE
## Complete Learning Path with References & Daily Objectives
## Optimized for Beginners with Python Focus | Lá»™ TrÃ¬nh 10 NgÃ y

---

## ğŸ“‹ OVERVIEW / Tá»”NG QUAN

**Total Duration:** 10 days (intensive)
**Daily Time Commitment:** 4-6 hours
**Learning Approach:** Theory + NotebookLM Q&A + Python Hands-on
**Target:** From beginner to practical Six Sigma analyst

**Lá»™ TrÃ¬nh Tá»•ng QuÃ¡t:**
- **Giai Äoáº¡n 1 (NgÃ y 1-3):** DEFINE & LEAN (TÆ° duy & Ná»n táº£ng)
- **Giai Äoáº¡n 2 (NgÃ y 4-6):** MEASURE (Äo lÆ°á»ng sá»± tháº­t)
- **Giai Äoáº¡n 3 (NgÃ y 7-8):** ANALYZE (PhÃ¢n tÃ­ch & NguyÃªn nhÃ¢n)
- **Giai Äoáº¡n 4 (NgÃ y 9-10):** IMPROVE & CONTROL (Cáº£i tiáº¿n & Kiá»ƒm soÃ¡t)

---

---

# GIAI ÄOáº N 1: DEFINE & LEAN (TÆ¯ DUY & Ná»€N Táº¢NG)
## NgÃ y 1-3: Thiáº¿t láº­p tÆ° duy Six Sigma

---

## NGÃ€Y 1: Tá»•ng Quan Six Sigma & TÆ° Duy Lean
### Day 1: Six Sigma Overview & Lean Mindset

**Duration:** 5-6 hours
**Objective:** Hiá»ƒu DMAIC, biáº¿t 8 loáº¡i lÃ£ng phÃ­, náº¯m vai trÃ² Belt

---

### PART 1A: LÃ½ Thuyáº¿t (2 hours)

**Topics:**

#### 1. Six Sigma Definition & History
- **Definition:** Data-driven methodology Ä‘á»ƒ cáº£i tiáº¿n quy trÃ¬nh (3.4 DPMO = 99.99966% tá»‘t)
- **History:** Motorola (1980s) â†’ General Electric (1990s) â†’ ToÃ n cáº§u
- **Statistically:** 6 sigma tá»« trung bÃ¬nh = 1 lá»—i / 1 triá»‡u

**Reference:**
```
ğŸ“˜ ASQ Black Belt Body of Knowledge (BBBOK)
   Section: Introduction to Six Sigma
ğŸ“˜ ISCCA Six Sigma Training Materials
   Chapter: Foundations of Six Sigma
```

#### 2. DMAIC Roadmap (SÆ¡ Äá»“ 5 BÆ°á»›c)
```
DEFINE        MEASURE       ANALYZE       IMPROVE       CONTROL
â”‚             â”‚             â”‚             â”‚             â”‚
Problem       Data          Root          Solutions     Sustain
Charter       Quality       Cause         Implement     Monitor
â”‚             â”‚             â”‚             â”‚             â”‚
Week 1        Week 2        Week 3        Week 4        Week 5+
```

**Chi tiáº¿t má»—i bÆ°á»›c:**
- **D (Define):** Project Charter, VOC â†’ CTQ, SIPOC
- **M (Measure):** Data Collection Plan, MSA, Capability Analysis
- **A (Analyze):** Hypothesis Tests, Root Cause (Fishbone, 5 Whys)
- **I (Improve):** DOE, Solution Selection, Pilot Test
- **C (Control):** SPC, Control Plan, Documentation

#### 3. Belt Roles (Vai TrÃ²)
| Belt Level | Role | Certification |
|-----------|------|---|
| **White** | Understand basics | ~1 week |
| **Yellow** | Support projects, apply tools | ~20 hours |
| **Green** | Lead improvement projects (part-time) | ~20 days |
| **Black** | Lead strategic projects (full-time) | ~20 days |
| **Master Black** | Train & coach Black Belts | 5+ years experience |

#### 4. The 8 Wastes of Lean (8 Loáº¡i LÃ£ng PhÃ­ - DOWNTIME)
```
D = Defects (Lá»—i sáº£n pháº©m)
O = Overproduction (Sáº£n xuáº¥t thá»«a)
W = Waiting (Chá» Ä‘á»£i)
N = Non-utilized Talent (LÃ£ng phÃ­ nhÃ¢n tÃ i)
T = Transportation (Váº­n chuyá»ƒn khÃ´ng cáº§n thiáº¿t)
I = Inventory (HÃ ng tá»“n kho)
M = Motion (Chuyá»ƒn Ä‘á»™ng khÃ´ng cáº§n thiáº¿t)
E = Extra Processing (Xá»­ lÃ½ thÃªm khÃ´ng cáº§n)
```

**VÃ­ Dá»¥ Thá»±c Táº¿ (Trong Software Engineering):**
| Waste | Manufacturing | Software |
|-------|---|---|
| Defects | Lá»—i sáº£n xuáº¥t | Bug, lá»—i code |
| Overproduction | Sáº£n xuáº¥t quÃ¡ má»©c | Build/deploy khÃ´ng cáº§n |
| Waiting | Chá» tÃ i nguyÃªn | Chá» review, merge PR |
| Non-utilized | LÃ£ng phÃ­ ká»¹ nÄƒng | Dev khÃ´ng tá»± quyáº¿t Ä‘á»‹nh |
| Transportation | Váº­n chuyá»ƒn | Chuyá»ƒn tiáº¿p giá»¯a team |
| Inventory | HÃ ng tá»“n | Code chÆ°a deploy |
| Motion | Chuyá»ƒn Ä‘á»™ng khÃ´ng cáº§n | Thao tÃ¡c UI láº·p láº¡i |
| Extra Processing | Xá»­ lÃ½ thÃªm | Code redundant, comments thá»«a |

---

### PART 1B: NotebookLM Q&A (1.5 hours)

**Prompt 1:** 
```
Dá»±a trÃªn file Cheat Sheet vá» Six Sigma, hÃ£y Ä‘Ã³ng vai giÃ¡m kháº£o:
- Há»i tÃ´i vá» 8 loáº¡i lÃ£ng phÃ­ (DOWNTIME)
- Náº¿u tÃ´i sai, giáº£i thÃ­ch láº¡i
- ÄÆ°a ra vÃ­ dá»¥ thá»±c táº¿ tá»« ngÃ nh pháº§n má»m hoáº·c sáº£n xuáº¥t
- YÃªu cáº§u tÃ´i xÃ¡c Ä‘á»‹nh Ä‘Ã³ lÃ  loáº¡i lÃ£ng phÃ­ nÃ o

VÃ­ dá»¥: "Má»™t team dev pháº£i chá» 2 tuáº§n Ä‘á»ƒ cÃ³ mÃ´i trÆ°á»ng test. 
ÄÃ¢y lÃ  lÃ£ng phÃ­ gÃ¬?" â†’ TÃ´i tráº£ lá»i â†’ Báº¡n cháº¥m Ä‘iá»ƒm
```

**Expected Outcome:**
- Báº¡n nhá»› Ä‘Æ°á»£c táº¥t cáº£ 8 loáº¡i lÃ£ng phÃ­
- CÃ³ thá»ƒ nháº­n diá»‡n lÃ£ng phÃ­ trong cÃ´ng viá»‡c hÃ ng ngÃ y

---

### PART 1C: Python (KhÃ´ng cÃ³)
**LÃ½ do:** NgÃ y 1 táº­p trung tÆ° duy, khÃ´ng cáº§n code

---

### PART 1D: Summary Checklist
- [ ] Hiá»ƒu DMAIC lÃ  gÃ¬
- [ ] Nhá»› 8 loáº¡i lÃ£ng phÃ­ (DOWNTIME)
- [ ] Biáº¿t Ä‘iá»ƒm khÃ¡c giá»¯a cÃ¡c Belt level
- [ ] CÃ³ thá»ƒ cho vÃ­ dá»¥ lÃ£ng phÃ­ trong cÃ´ng viá»‡c cá»§a báº¡n

**References Used:**
```
ğŸ“˜ FILE 1 [170] - Python-For-Six-Sigma-Complete-Bilingual.md
   SECTION 1: Introduction to Six Sigma
ğŸ“˜ ASQ BBBOK - Chapter 1: Overview & Methodology
ğŸ“˜ ISCCA Materials - Introduction to Lean Six Sigma
```

---

---

## NGÃ€Y 2: CÃ´ng Cá»¥ Lean & Thá»‘ng KÃª CÆ¡ Báº£n
### Day 2: Lean Tools & Basic Statistics

**Duration:** 5-6 hours
**Objective:** Biáº¿t 5S, Kaizen, Poka-Yoke, thá»‘ng kÃª mÃ´ táº£, váº½ histogram

---

### PART 2A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Lean Tools (CÃ´ng Cá»¥ Lean)

**5S Method (Sáº¯p xáº¿p, Sáº¡ch sáº½, Sáº¯p hÃ ng, SÆ¡ Ä‘á»“ hÃ³a, Sá»± ká»· luáº­t)**
```
S1: SEIRI (Sort - Sáº¯p xáº¿p)
    â†’ XÃ³a nhá»¯ng gÃ¬ khÃ´ng cáº§n
    â†’ VÃ­ dá»¥: XÃ³a code dead, unused variables
    
S2: SEITON (Set - Sáº¯p hÃ ng)
    â†’ Sáº¯p xáº¿p Ä‘á»ƒ dá»… tÃ¬m
    â†’ VÃ­ dá»¥: Tá»• chá»©c folder project logic, naming convention
    
S3: SEISO (Shine - Sáº¡ch sáº½)
    â†’ LÃ m sáº¡ch/maintain
    â†’ VÃ­ dá»¥: Code review, refactor, clean up logs
    
S4: SEIKETSU (Standardize - SÆ¡ Ä‘á»“ hÃ³a)
    â†’ Táº¡o quy trÃ¬nh chuáº©n
    â†’ VÃ­ dá»¥: Development standards, code style guide
    
S5: SHITSUKE (Sustain - Sá»± ká»· luáº­t)
    â†’ Duy trÃ¬ liÃªn tá»¥c
    â†’ VÃ­ dá»¥: Daily standup, code quality checks
```

**Kaizen (Continuous Improvement - Cáº£i tiáº¿n LiÃªn Tá»¥c)**
- **Triáº¿t lÃ½:** Nhá», Ä‘Æ¡n giáº£n, liÃªn tá»¥c lÃ  tá»‘t hÆ¡n lá»›n, phá»©c táº¡p, má»™t láº§n
- **Method:** Plan-Do-Check-Act (PDCA)
- **VÃ­ dá»¥:** Má»—i sprint, team cáº£i tiáº¿n má»™t quy trÃ¬nh nhá»

**Poka-Yoke (Mistake-Proofing - Chá»‘ng Lá»—i)**
- **Ã tÆ°á»Ÿng:** Thiáº¿t káº¿ Ä‘á»ƒ khÃ´ng thá»ƒ sai
- **VÃ­ dá»¥ trong Software:**
  - Type checking (TypeScript thay vÃ¬ JavaScript)
  - Input validation (khÃ´ng cho nháº­p sá»‘ Ã¢m náº¿u khÃ´ng há»£p lá»‡)
  - Code review checklist
  - Automated tests trÆ°á»›c khi merge

**Visual Management (Quáº£n LÃ½ HÃ¬nh áº¢nh)**
- **Ã tÆ°á»Ÿng:** Má»i ngÆ°á»i nhÃ¬n vÃ o lÃ  hiá»ƒu tÃ¬nh tráº¡ng
- **VÃ­ dá»¥:**
  - Dashboard hiá»ƒn thá»‹ build status
  - Kanban board (To Do, Doing, Done)
  - Burndown chart (Sprint progress)

**Reference:**
```
ğŸ“˜ ASQ BBBOK - Section: Lean Principles
ğŸ“˜ ISCCA Materials - Chapter: Lean Tools & Techniques
```

#### 2. Descriptive Statistics (Thá»‘ng KÃª MÃ´ Táº£)

**Key Metrics:**
```
Mean (Î¼)           = Trung bÃ¬nh sá»‘ há»c
Median             = GiÃ¡ trá»‹ á»Ÿ giá»¯a (50%)
Mode               = GiÃ¡ trá»‹ xuáº¥t hiá»‡n nhiá»u nháº¥t
Standard Dev (Ïƒ)   = Äá»™ phÃ¢n tÃ¡n (máº·c Ä‘á»‹nh Ä‘á»ƒ test chuáº©n hÃ³a)
Variance (ÏƒÂ²)      = BÃ¬nh phÆ°Æ¡ng Ä‘á»™ phÃ¢n tÃ¡n
Range              = Max - Min (Khoáº£ng)
IQR                = Q3 - Q1 (Tá»© phÃ¢n vá»‹)
Skewness           = Äá»™ xiÃªn (Ã¢m = lá»‡ch trÃ¡i, dÆ°Æ¡ng = lá»‡ch pháº£i)
Kurtosis           = Äá»™ nhá»n (peak hoáº·c flat)
```

**PhÃ¢n Phá»‘i Chuáº©n (Normal Distribution - Gaussian)**
```
       Bell curve / ÄÆ°á»ng chuÃ´ng
           â†‘
      68% |    ###
           |   #####
      95% |  #######
           | #########
      99% |###########
           |____________
        -3Ïƒ -2Ïƒ -1Ïƒ  0  +1Ïƒ +2Ïƒ +3Ïƒ
        
NgoÃ i Â±3Ïƒ = Outliers (báº¥t thÆ°á»ng)
NgoÃ i Â±6Ïƒ = Lá»—i hoáº·c dá»¯ liá»‡u sai
```

---

### PART 2B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
HÃ£y giáº£i thÃ­ch cho tÃ´i:
1. Poka-Yoke lÃ  gÃ¬? Cho vÃ­ dá»¥ Ã¡p dá»¥ng trong láº­p trÃ¬nh Python.
2. Sá»± khÃ¡c biá»‡t giá»¯a Mean, Median, Mode lÃ  gÃ¬?
3. Khi nÃ o nÃªn dÃ¹ng Mean? Khi nÃ o nÃªn dÃ¹ng Median?

VÃ­ dá»¥: "LÆ°Æ¡ng cá»§a 10 nhÃ¢n viÃªn: $40k, $45k, $50k, $50k, $55k, 
$60k, $65k, $70k, $75k, $1M"
HÃ£y tÃ­nh Mean, Median, Mode. CÃ¡i nÃ o pháº£n Ã¡nh thá»±c táº¿ hÆ¡n?
```

**Expected Outcome:**
- Hiá»ƒu tháº¿ nÃ o lÃ  "lá»—i proof" design
- Biáº¿t Mean cÃ³ thá»ƒ bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outlier
- Median lÃ  cÃ¢n báº±ng hÆ¡n khi cÃ³ extreme values

---

### PART 2C: Python Hands-on (1.5 hours)

**Task 1: Create a Dataset**
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Simulate: Code build time (in minutes) for 100 builds
np.random.seed(42)
build_times = np.random.normal(loc=5, scale=1.2, size=100)
build_times = np.abs(build_times)  # Ensure positive

df = pd.DataFrame({
    'build_number': range(1, 101),
    'build_time_minutes': build_times
})

print(df.head())
print(f"Total builds: {len(df)}")
```

**Task 2: Descriptive Statistics**
```python
# Calculate all statistics
stats = df['build_time_minutes'].describe()
print(stats)

# Custom statistics
print(f"Mean: {df['build_time_minutes'].mean():.2f} min")
print(f"Median: {df['build_time_minutes'].median():.2f} min")
print(f"Mode: {df['build_time_minutes'].mode().values[0]:.2f} min")
print(f"Std Dev: {df['build_time_minutes'].std():.2f} min")
print(f"Variance: {df['build_time_minutes'].var():.2f}")
print(f"Range: {df['build_time_minutes'].max() - df['build_time_minutes'].min():.2f} min")
print(f"IQR: {df['build_time_minutes'].quantile(0.75) - df['build_time_minutes'].quantile(0.25):.2f} min")
```

**Task 3: Visualization**
```python
# Histogram + Normal Distribution
plt.figure(figsize=(12, 6))

# Histogram
plt.hist(df['build_time_minutes'], bins=30, edgecolor='black', alpha=0.7, label='Build times')

# Overlay normal distribution
from scipy.stats import norm
mu = df['build_time_minutes'].mean()
sigma = df['build_time_minutes'].std()
x = np.linspace(df['build_time_minutes'].min(), df['build_time_minutes'].max(), 100)
plt.plot(x, norm.pdf(x, mu, sigma) * len(df) * (df['build_time_minutes'].max() - df['build_time_minutes'].min()) / 30, 
         'r-', linewidth=2, label='Normal Distribution')

plt.xlabel('Build Time (minutes)')
plt.ylabel('Frequency')
plt.title('Distribution of Build Times')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# Statistical summary
print(f"\n=== DISTRIBUTION ANALYSIS ===")
print(f"Distribution is roughly normal? {abs(df['build_time_minutes'].skew()) < 0.5}")
```

**Task 4: Outlier Detection (5S - Identify what to remove)**
```python
# Find outliers using 3-sigma rule
lower_bound = mu - 3*sigma
upper_bound = mu + 3*sigma

outliers = df[(df['build_time_minutes'] < lower_bound) | (df['build_time_minutes'] > upper_bound)]
print(f"Outliers (>3Ïƒ): {len(outliers)} builds")
print(outliers)

# Interpretation: These are "Special Causes" - investigate why these builds took so long
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 4: Basic Statistics
ğŸ“˜ FILE 2 [171] - DATA LOADING & BASIC OPERATIONS
ğŸ“˜ FILE 3 [172] - EXAMPLE 2: Descriptive Statistics
```

---

### PART 2D: Summary Checklist
- [ ] Hiá»ƒu 5S lÃ  gÃ¬ vÃ  cÃ¡ch Ã¡p dá»¥ng
- [ ] Biáº¿t sá»± khÃ¡c biá»‡t Mean vs Median vs Mode
- [ ] Cháº¡y Ä‘Æ°á»£c pandas describe() trÃªn dataset
- [ ] Váº½ Ä‘Æ°á»£c histogram vá»›i distribution overlay
- [ ] PhÃ¡t hiá»‡n Ä‘Æ°á»£c outlier báº±ng 3-sigma rule

---

---

## NGÃ€Y 3: DEFINE - XÃ¡c Äá»‹nh Dá»± Ãn & KhÃ¡ch HÃ ng
### Day 3: DEFINE - Project Charter, VOC to CTQ, SIPOC

**Duration:** 5-6 hours
**Objective:** Viáº¿t Project Charter, biáº¿n VOC thÃ nh CTQ, váº½ SIPOC

---

### PART 3A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Project Charter (Hiáº¿n ChÆ°Æ¡ng Dá»± Ãn)

**Components:**

**A. Business Case (LÃ½ Do Kinh Doanh)**
- Táº¡i sao dá»± Ã¡n nÃ y láº¡i cáº§n thiáº¿t?
- ROI (Return on Investment) ká»³ vá»ng?
- VÃ­ dá»¥: "Giáº£m bug tá»« 10% xuá»‘ng 2% = Tiáº¿t kiá»‡m $50k/nÄƒm"

**B. Problem Statement (PhÃ¡t Biá»ƒu Váº¥n Äá»)**
- Váº¥n Ä‘á» cá»¥ thá»ƒ lÃ  gÃ¬?
- Dá»¯ liá»‡u hiá»‡n tráº¡ng?
- Scope (Pháº¡m vi)?

**VÃ­ dá»¥ tá»‘t:**
```
âŒ BAD: "Cháº¥t lÆ°á»£ng code khÃ´ng tá»‘t"
âœ… GOOD: "Module authentication cÃ³ 15% lá»—i per sprint, 
        cao hÆ¡n 2% cá»§a module khÃ¡c. NguyÃªn nhÃ¢n: 
        thiáº¿u unit test (5%), code review khÃ´ng ká»¹ (7%), 
        kiáº¿n trÃºc cÅ© (3%)"
```

**C. Goal Statement (Má»¥c TiÃªu)**
- SMART: Specific, Measurable, Achievable, Relevant, Time-bound
- Baseline vs Target

**VÃ­ dá»¥:**
```
Baseline: 15% defect rate
Target:   < 5% defect rate
Timeline: 3 months (by end of Q2)
Success: Táº¥t cáº£ module Ä‘á»u < 5%
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - DEFINE Phase: Project Charter
ğŸ“˜ ISCCA Materials - Chapter: Defining the Project
ğŸ“˜ FILE 1 [170] - SECTION 3: DEFINE Phase
```

#### 2. VOC to CTQ (Voice of Customer â†’ Critical to Quality)

**VOC (Tiáº¿ng NÃ³i KhÃ¡ch HÃ ng)** = Äiá»u khÃ¡ch hÃ ng nÃ³i
- Cháº¥t lÆ°á»£ng code tá»‘t
- á»¨ng dá»¥ng load nhanh
- Dá»… sá»­ dá»¥ng

**CTQ (YÃªu Cáº§u Ká»¹ Thuáº­t Äo ÄÆ°á»£c)** = Biáº¿n VOC thÃ nh con sá»‘
- Cháº¥t lÆ°á»£ng code â†’ Defect rate < 2% / Cyclomatic complexity < 10
- Load nhanh â†’ Page load time < 2 seconds / API response time < 100ms
- Dá»… sá»­ dá»¥ng â†’ User can complete task in < 3 clicks / NPS > 8

**Process:**
```
VOC (Qualitative)
    â†“
CTQ (Quantitative)
    â†“
Measurement (LSL, USL, Target)
```

**Example Table:**

| VOC | CTQ | LSL | Target | USL |
|-----|-----|-----|--------|-----|
| Code quality | Defect rate | 0% | 1% | 5% |
| Performance | API response (ms) | - | 100 | 500 |
| Usability | Clicks to complete | - | 3 | 10 |
| Reliability | Uptime | 99% | 99.9% | - |

#### 3. SIPOC Diagram (Supplier-Input-Process-Output-Customer)

```
SUPPLIER  â†’  INPUT  â†’  PROCESS  â†’  OUTPUT  â†’  CUSTOMER
   â†“           â†“         â†“          â†“           â†“
Who         What's      Main      What's      Who
provides    needed      steps      delivered  uses
input                              it

Example (Code Review Process):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dev       PR Code      1. Create PR    Approved  Dev Team
Team    + Review       2. Review code  Code      + Product
          List         3. Test         + Tests   Manager
                       4. Merge
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - DEFINE Phase: SIPOC Analysis
ğŸ“˜ ISCCA Materials - Process Mapping Tools
ğŸ“˜ FILE 1 [170] - SECTION 3: DEFINE Phase examples
```

---

### PART 3B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
TÃ´i muá»‘n lÃ m dá»± Ã¡n: "Giáº£m bug trong module payment tá»« 8% xuá»‘ng 2%"

HÃ£y giÃºp tÃ´i:
1. Viáº¿t Project Charter vá»›i Business Case, Problem Statement, Goal Statement
2. Chuyá»ƒn VOC "Payment module á»•n Ä‘á»‹nh" thÃ nh CTQ cá»¥ thá»ƒ (vá»›i sá»‘ liá»‡u)
3. Váº½ SIPOC cho quy trÃ¬nh code review â†’ merge

Báº¡n hÃ£y:
- Há»i tÃ´i cÃ¡c cÃ¢u há»i chi tiáº¿t (What metrics? Why 2%? Timeline?)
- GiÃºp tÃ´i lÃ m Project Charter hoÃ n chá»‰nh
```

**Expected Outcome:**
- CÃ³ má»™t Project Charter Ä‘Ãºng quy chuáº©n
- VOC & CTQ rÃµ rÃ ng, cÃ³ sá»‘ liá»‡u
- Hiá»ƒu SIPOC lÃ  gÃ¬ vÃ  cÃ¡ch Ã¡p dá»¥ng

---

### PART 3C: Python Hands-on (1.5 hours)

**Task 1: Váº½ SIPOC Diagram báº±ng Graphviz**

```python
from graphviz import Digraph

# Create SIPOC diagram
dot = Digraph(comment='SIPOC - Code Review Process', format='png')
dot.attr(rankdir='LR')
dot.attr('node', shape='box', style='rounded,filled', fillcolor='lightblue')

# Add nodes
dot.node('S', 'SUPPLIER\nDeveloper', shape='ellipse')
dot.node('I', 'INPUT\n- Code\n- Checklist', shape='box')
dot.node('P', 'PROCESS\n1. Create PR\n2. Review\n3. Approve\n4. Merge', shape='box')
dot.node('O', 'OUTPUT\n- Clean code\n- Test passed', shape='box')
dot.node('C', 'CUSTOMER\nProduct Team', shape='ellipse')

# Add edges
dot.edge('S', 'I')
dot.edge('I', 'P')
dot.edge('P', 'O')
dot.edge('O', 'C')

# Render
dot.render('sipoc_diagram', cleanup=True)
print("SIPOC diagram saved as sipoc_diagram.png")
```

**Task 2: VOC to CTQ Mapping**

```python
import pandas as pd

# Create VOC to CTQ mapping
voc_ctq = pd.DataFrame({
    'VOC (Customer Need)': [
        'Code quality is high',
        'Application is fast',
        'System is reliable',
        'Easy to maintain'
    ],
    'CTQ (Measurable)': [
        'Defect rate',
        'API response time',
        'System uptime',
        'Code coverage'
    ],
    'Unit': [
        'percent (%)',
        'milliseconds (ms)',
        'percent (%)',
        'percent (%)'
    ],
    'LSL': [
        '0%',
        '0',
        '99%',
        '70%'
    ],
    'Target': [
        '1%',
        '100',
        '99.9%',
        '85%'
    ],
    'USL': [
        '5%',
        '500',
        '-',
        '-'
    ]
})

print(voc_ctq.to_string(index=False))

# Save to CSV
voc_ctq.to_csv('voc_ctq_mapping.csv', index=False)
print("\nVOC-CTQ mapping saved to voc_ctq_mapping.csv")
```

**Task 3: Project Charter Template**

```python
# Create Project Charter document
charter = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                   PROJECT CHARTER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT NAME: Reduce Payment Module Defects to < 2%
PROJECT SPONSOR: VP Engineering
PROJECT LEADER: [Your Name]
START DATE: [Date]
TARGET END DATE: [+3 months]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. BUSINESS CASE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Current State:
- Payment module has 8% defect rate
- Cost of defects: $50k/quarter in lost revenue & support
- Impact: 2% of all transactions fail on first attempt

Desired State:
- Payment module < 2% defect rate (industry standard)
- Estimated savings: $40k/quarter
- ROI: 4:1 (Investment vs Benefit)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2. PROBLEM STATEMENT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CURRENT PERFORMANCE:
- Baseline: 8% defect rate
- Benchmark: Industry average 2%
- Gap: 6% (4x worse than expected)

ROOT CAUSES (Preliminary):
- 40% from edge cases not covered in tests
- 35% from integration issues between services
- 25% from insufficient code review

SCOPE:
- Module: Payment processing (in-scope)
- Excluded: Payment UI, Admin dashboard
- Timeline: 3 months

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3. GOAL STATEMENT (SMART)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

By [End Date], the Payment Module will achieve:
âœ“ Defect Rate: 8% â†’ < 2%
âœ“ Mean Time To Resolution (MTTR): 4 hours â†’ < 1 hour
âœ“ Test Coverage: 65% â†’ > 85%
âœ“ Code Review Cycle: 24 hours â†’ < 8 hours

Success Criteria:
- All metrics achieved by target date
- Sustained for 2 consecutive months post-project
- Zero critical bugs in production

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
4. BENEFITS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Quantitative:
- $40k quarterly savings
- 98% transaction success (up from 92%)

Qualitative:
- Improved customer trust
- Better team morale
- Reduced firefighting

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5. TEAM & RESOURCES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Black Belt: [Your Name]
Green Belts: 2 senior engineers
Contributors: QA team, DevOps
Budget: $15k (tools, training)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

print(charter)

# Save to file
with open('project_charter.txt', 'w') as f:
    f.write(charter)
print("Project Charter saved to project_charter.txt")
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 3: DEFINE Phase
ğŸ“˜ FILE 2 [171] - Quick Reference: SIPOC, VOC-CTQ
ğŸ“˜ FILE 5 [174] - FAQ: Project Charter examples
```

---

### PART 3D: Summary Checklist
- [ ] Viáº¿t Ä‘Æ°á»£c Project Charter hoÃ n chá»‰nh (Business Case + Problem Statement + Goal)
- [ ] Chuyá»ƒn VOC thÃ nh CTQ cá»¥ thá»ƒ
- [ ] Váº½ Ä‘Æ°á»£c SIPOC diagram
- [ ] Hiá»ƒu vai trÃ² má»—i pháº§n trong DEFINE

---

---

# GIAI ÄOáº N 2: MEASURE (ÄO LÆ¯á»œNG Sá»° THáº¬T)
## NgÃ y 4-6: Thu Tháº­p & PhÃ¢n TÃ­ch Dá»¯ Liá»‡u

---

## NGÃ€Y 4: Thu Tháº­p Dá»¯ Liá»‡u & Káº¿ Hoáº¡ch Láº¥y Máº«u
### Day 4: Data Collection & Sampling Plan

**Duration:** 5-6 hours
**Objective:** Hiá»ƒu Continuous vs Discrete data, táº¡o Data Collection Plan

---

### PART 4A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Types of Data (Loáº¡i Dá»¯ Liá»‡u)

**A. CONTINUOUS (LiÃªn Tá»¥c) - Äo Ä‘Æ°á»£c giá»¯a cÃ¡c Ä‘iá»ƒm**
```
VÃ­ dá»¥: 5.2, 5.25, 5.251, 5.2511...
- Build time: 4.5 minutes
- API response time: 123.45 ms
- Customer age: 32.7 years
- Temperature: 25.3Â°C

Äáº·c Ä‘iá»ƒm: VÃ´ háº¡n sá»‘ tháº­p phÃ¢n (trong lÃ½ thuyáº¿t)
```

**B. DISCRETE (Rá»i Ráº¡c) - Chá»‰ lÃ  sá»‘ nguyÃªn**
```
VÃ­ dá»¥: 1, 2, 3, ... (khÃ´ng cÃ³ 1.5 lá»—i)
- Number of defects: 3 bugs
- Customer count: 150 people
- Test failures: 5 tests failed
- Delivery status: 1=on-time, 0=late

Äáº·c Ä‘iá»ƒm: CÃ³ sá»‘ Ã­t nháº¥t, Ä‘áº¿m Ä‘Æ°á»£c
```

**C. CATEGORICAL (PhÃ¢n Loáº¡i) - KhÃ´ng pháº£i sá»‘**
```
VÃ­ dá»¥:
- Environment: Dev, Staging, Prod
- Status: Pass, Fail, Pending
- Team: Backend, Frontend, DevOps
```

**Impact on Analysis:**
```
Data Type     â†’ Test Type       â†’ Chart Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Continuous    â†’ t-test, ANOVA   â†’ Histogram, Boxplot
Discrete      â†’ Chi-square      â†’ Bar chart
Categorical   â†’ Chi-square      â†’ Frequency table
```

#### 2. Data Collection Plan (Káº¿ Hoáº¡ch Thu Tháº­p Dá»¯ Liá»‡u)

**Components:**

| Component | Example |
|-----------|---------|
| **What** | Build time, defect count, API response |
| **Where** | Production environment, staging, dev |
| **When** | Daily 9-5, all shifts, all days |
| **Who** | Automated tool (Jenkins), QA manual |
| **How** | Logs, database query, manual inspection |
| **Sample Size** | 100 builds, 500 transactions |
| **Frequency** | Real-time, hourly, daily |

**Example Plan:**
```
Project: Reduce Payment Module Defects
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

METRIC 1: Defect Rate
  What:       Count of defects per transaction
  Where:      Production payment API
  When:       24/7 monitoring
  How:        Error logs aggregation
  Sample:     All transactions (no sampling)
  Collection: Automated via Datadog

METRIC 2: Build Time
  What:       Duration of full CI/CD pipeline
  Where:      Jenkins CI server
  When:       Each code push (M-F 9-5 initially)
  How:        Jenkins API metrics
  Sample:     100 consecutive builds
  Collection: Automated daily export
```

#### 3. Sampling Methods (PhÆ°Æ¡ng PhÃ¡p Láº¥y Máº«u)

**When to Sample:**
- Population too large (millions of transactions)
- Measurement destructive (can't test all)
- Time/cost constraint

**Methods:**

| Method | Example | Pros | Cons |
|--------|---------|------|------|
| **Random** | Every nth item randomly | Unbiased | Can miss patterns |
| **Stratified** | 25% from each environment | Ensures coverage | More complex |
| **Systematic** | Every 10th item | Simple | Periodic bias risk |
| **Cluster** | All orders from one day | Quick | May be biased |

**Reference:**
```
ğŸ“˜ ASQ BBBOK - MEASURE Phase: Data Collection & Sampling
ğŸ“˜ ISCCA Materials - Chapter: Measurement Planning
ğŸ“˜ FILE 1 [170] - SECTION 4: MEASURE Phase
```

---

### PART 4B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
TÃ´i Ä‘ang quáº£n lÃ½ dá»± Ã¡n "Monitor API Performance".

HÃ£y giÃºp tÃ´i:
1. XÃ¡c Ä‘á»‹nh dá»¯ liá»‡u nÃ o lÃ  Continuous, Discrete, Categorical
   - API response time
   - HTTP status code (200, 404, 500)
   - Error message text
   - Request count per minute
   - Server location (US, EU, Asia)
   
2. Táº¡o Data Collection Plan cho API monitoring
   - Quy trÃ¬nh thu tháº­p?
   - Táº§n suáº¥t?
   - KÃ­ch thÆ°á»›c máº«u?
   
3. Khi nÃ o nÃªn dÃ¹ng Random vs Stratified sampling?
```

**Expected Outcome:**
- PhÃ¢n loáº¡i Ä‘Æ°á»£c Continuous, Discrete, Categorical
- Táº¡o Ä‘Æ°á»£c Data Collection Plan chi tiáº¿t
- Biáº¿t khi nÃ o dÃ¹ng sampling nÃ o

---

### PART 4C: Python Hands-on (1.5 hours)

**Task 1: Create Data Collection Plan Checklist**

```python
import pandas as pd

# Data Collection Plan Template
collection_plan = pd.DataFrame({
    'Metric': [
        'Defect Rate',
        'Build Time',
        'API Response Time',
        'Test Coverage',
        'Code Review Cycle'
    ],
    'Data Type': [
        'Discrete (count)',
        'Continuous (time)',
        'Continuous (time)',
        'Continuous (percent)',
        'Continuous (time)'
    ],
    'Source': [
        'Error logs',
        'Jenkins',
        'APM tool',
        'Coverage report',
        'GitHub'
    ],
    'Frequency': [
        'Real-time',
        'Per build',
        'Per request',
        'Per PR',
        'Per PR'
    ],
    'Sample Method': [
        'All data',
        'All builds',
        'All requests',
        'All PRs',
        'All PRs'
    ],
    'Target Size': [
        '10,000+',
        '100+',
        '50,000+',
        '50+',
        '50+'
    ]
})

print("DATA COLLECTION PLAN")
print("=" * 100)
print(collection_plan.to_string(index=False))

# Save to CSV
collection_plan.to_csv('data_collection_plan.csv', index=False)
```

**Task 2: Random Sampling Implementation**

```python
import pandas as pd
import numpy as np

# Simulate large dataset (10,000 transactions)
np.random.seed(42)
large_dataset = pd.DataFrame({
    'transaction_id': range(1, 10001),
    'response_time_ms': np.random.normal(150, 50, 10000),
    'status_code': np.random.choice([200, 400, 500], 10000, p=[0.95, 0.03, 0.02]),
    'user_region': np.random.choice(['US', 'EU', 'Asia'], 10000)
})

print(f"Total dataset size: {len(large_dataset)}")

# Method 1: Random sampling (nhanh, Ä‘Æ¡n giáº£n)
sample_random = large_dataset.sample(n=100, random_state=42)
print(f"\nRandom sample size: {len(sample_random)}")
print(f"Response time (sample): mean={sample_random['response_time_ms'].mean():.2f} ms")

# Method 2: Stratified sampling by region
sample_stratified = large_dataset.groupby('user_region', group_keys=False).apply(
    lambda x: x.sample(n=max(1, int(len(x) * 0.01)), random_state=42)  # 1% from each region
)
print(f"\nStratified sample size: {len(sample_stratified)}")
print(f"Sample composition:\n{sample_stratified['user_region'].value_counts()}")

# Method 3: Systematic sampling (every nth item)
n = len(large_dataset) // 100  # Get 100 samples
sample_systematic = large_dataset.iloc[::n]
print(f"\nSystematic sample size: {len(sample_systematic)}")
```

**Task 3: Data Quality Baseline**

```python
# Establish baseline metrics from sample
sample = large_dataset.sample(n=500, random_state=42)

baseline_metrics = {
    'Response Time': {
        'mean': sample['response_time_ms'].mean(),
        'std': sample['response_time_ms'].std(),
        'p50': sample['response_time_ms'].quantile(0.50),
        'p95': sample['response_time_ms'].quantile(0.95),
        'p99': sample['response_time_ms'].quantile(0.99)
    },
    'Success Rate': {
        'total': len(sample),
        'success': (sample['status_code'] == 200).sum(),
        'success_rate': (sample['status_code'] == 200).sum() / len(sample) * 100
    }
}

print("=" * 60)
print("BASELINE METRICS (From Sample)")
print("=" * 60)
print(f"\nResponse Time Statistics:")
for key, value in baseline_metrics['Response Time'].items():
    print(f"  {key:12}: {value:.2f} ms")

print(f"\nSuccess Rate:")
for key, value in baseline_metrics['Success Rate'].items():
    if key == 'success_rate':
        print(f"  {key:12}: {value:.2f}%")
    else:
        print(f"  {key:12}: {value}")

print("\n" + "=" * 60)
print("TARGET IMPROVEMENTS")
print("=" * 60)
target_p95 = baseline_metrics['Response Time']['p95'] * 0.8  # Reduce by 20%
target_success = baseline_metrics['Success Rate']['success_rate'] + 2  # Increase by 2%

print(f"P95 Response Time: {baseline_metrics['Response Time']['p95']:.2f} ms â†’ {target_p95:.2f} ms")
print(f"Success Rate: {baseline_metrics['Success Rate']['success_rate']:.2f}% â†’ {target_success:.2f}%")
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 4: Data Collection & Sampling
ğŸ“˜ FILE 2 [171] - Data Loading & Data Quality Checking
ğŸ“˜ FILE 4 [174] - FAQ: Missing Values, Data Quality
```

---

### PART 4D: Summary Checklist
- [ ] PhÃ¢n loáº¡i Ä‘Æ°á»£c Continuous vs Discrete data
- [ ] Táº¡o Ä‘Æ°á»£c Data Collection Plan
- [ ] Cháº¡y Ä‘Æ°á»£c random sampling code
- [ ] Láº­p Ä‘Æ°á»£c baseline metrics

---

---

## NGÃ€Y 5: MSA - PhÃ¢n TÃ­ch Há»‡ Thá»‘ng Äo LÆ°á»ng (MEASUREMENT SYSTEM ANALYSIS)
### Day 5: MSA - Gage R&R Analysis

**Duration:** 5-6 hours (IMPORTANT DAY)
**Objective:** Hiá»ƒu Gage R&R, kiá»ƒm chá»©ng "cÃ¢n cÃ³ Ä‘Ãºng khÃ´ng" trÆ°á»›c khi phÃ¢n tÃ­ch

---

### PART 5A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Why MSA Matters (Táº¡i Sao Quan Trá»ng)

**Scenario (TÃ¬nh Huá»‘ng):**
```
Báº¡n Ä‘o Ä‘á»™ dÃ i 10 sáº£n pháº©m báº±ng 2 thÆ°á»›c:
  ThÆ°á»›c A: 10.1, 10.2, 10.3, 10.1, 10.2
  ThÆ°á»›c B: 9.8, 11.2, 10.5, 9.9, 10.8
  
Káº¿t luáº­n: ThÆ°á»›c B kÃ©m chÃ­nh xÃ¡c!

âš ï¸ KHÃ“A BÃ€I Há»ŒC: 
   Náº¿u há»‡ thá»‘ng Ä‘o khÃ´ng chÃ­nh xÃ¡c,
   má»i káº¿t luáº­n thá»‘ng kÃª Ä‘á»u sai!
```

**Analogy (Loáº¡i Tá»«):**
- Software testing: Unit test pháº£i "reliable" trÆ°á»›c khi integration test
- CI/CD: Code style check pháº£i Ä‘Ãºng trÆ°á»›c khi deploy
- Hardware: Calibration trÆ°á»›c khi production

#### 2. Accuracy vs Precision (Äá»™ ChÃ­nh XÃ¡c vs Äá»™ Láº·p Láº¡i)

```
Accuracy (Äá»™ ChÃ­nh XÃ¡c)
= Gáº§n vá»›i giÃ¡ trá»‹ tháº­t bao nhiÃªu
= Unbiased, no systematic error

Precision (Äá»™ Láº·p Láº¡i)  
= Äo láº·p láº¡i cÃ³ káº¿t quáº£ giá»‘ng khÃ´ng
= Variation, repeatability

Visual:

        Accurate   Precise    Both       None
         Only      Only      âœ“âœ“âœ“âœ—
           âœ“          âœ“        âœ“          âœ—
              âœ“          âœ“        âœ“          âœ—
            âœ“âœ“âœ“âœ—     âœ“âœ“âœ“âœ—    âœ“âœ“âœ“âœ“     âœ“âœ“âœ“âœ“
         
         Mean    Clustered  Perfect   Random
        Close    but Biased           off
```

#### 3. Gage R&R Components

**R&R = Repeatability + Reproducibility**

```
Repeatability (TÃ¡i Láº­p - Same Person, Same Equipment)
= Khi ngÆ°á»i A dÃ¹ng thÆ°á»›c A, dÃ² láº§n 1 vs láº§n 2 khÃ¡c nhau bao nhiÃªu?
= Variation trong há»‡ thá»‘ng (equipment, environmental)

Reproducibility (TÃ¡i Táº¡o - Same Part, Different Operators)
= Khi ngÆ°á»i A & B cÃ¹ng dÃ¹ng thÆ°á»›c A Ä‘o sáº£n pháº©m Ä‘Ã³, khÃ¡c nhau bao nhiÃªu?
= Variation giá»¯a cÃ¡c operator
```

**Acceptance Criteria:**

```
Gage R&R % = Total Variation tá»« R&R / Total Allowed Variation

< 10%  â†’ Excellent (Tá»‘t, cháº¥p nháº­n ngay)
10-30% â†’ Acceptable (CÃ²n Ä‘Æ°á»£c, cÃ³ thá»ƒ dÃ¹ng)
> 30%  â†’ Not Acceptable (Tá»‡, pháº£i cáº£i tiáº¿n há»‡ thá»‘ng Ä‘o)
```

**Example:**
```
Spec: 10mm Â± 1mm (LSL=9, USL=11)
Total Allowed Variation = USL - LSL = 2mm

Gage R&R variation = 0.15mm
Gage R&R % = (0.15 / 2) Ã— 100 = 7.5% âœ“ EXCELLENT

â†’ Há»‡ thá»‘ng Ä‘o tá»‘t, cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ phÃ¢n tÃ­ch quy trÃ¬nh
```

#### 4. Gage R&R Study Design

**Method 1: Crossed Design (Phá»• Biáº¿n)**
```
3 Operators Ã— 10 Parts Ã— 3 Replicates = 90 measurements

Operator A
  Part 1: 10.1, 10.1, 10.2
  Part 2: 9.8, 9.9, 9.8
  ...

Operator B
  Part 1: 10.3, 10.2, 10.3
  Part 2: 10.1, 10.0, 10.1
  ...

Operator C
  Part 1: 10.0, 10.0, 10.1
  Part 2: 9.7, 9.8, 9.8
  ...
```

**Method 2: Nested Design (Khi Máº«u Bá»‹ TiÃªu Thá»¥)**
```
VÃ­ dá»¥: Chá»©ng chá»‰ máº«u mÃ¡u â†’ KhÃ´ng thá»ƒ dÃ¹ng máº«u 1 láº§n thá»© 2
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - MEASURE Phase: Measurement System Analysis
ğŸ“˜ ISCCA Materials - MSA & Gage R&R
ğŸ“˜ FILE 1 [170] - SECTION 4: MSA & Gage R&R
```

---

### PART 5B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
Giáº£i thÃ­ch Gage R&R cho má»™t láº­p trÃ¬nh viÃªn:

1. "Measurement System" trong pháº§n má»m lÃ  gÃ¬?
   (Code quality metrics, test coverage, performance benchmarks)

2. TÆ°Æ¡ng tá»± nÃ o giá»¯a Gage R&R vÃ  Software Testing?
   (Repeatability = Test reliability / Reproducibility = Test across environments)

3. Náº¿u Test Framework bá»‹ "Gage R&R > 30%", Ä‘iá»u gÃ¬ sáº½ xáº£y ra?
   (Test results khÃ´ng tin cáº­y â†’ KhÃ´ng thá»ƒ detect real issues)

4. LÃ m sao "calibrate" test framework giá»‘ng nhÆ° calibrate thÆ°á»›c?
```

**Expected Outcome:**
- Hiá»ƒu Gage R&R khÃ´ng pháº£i chá»‰ cho pháº§n cá»©ng mÃ  cáº£ pháº§n má»m
- Biáº¿t khi nÃ o data quality lÃ  váº¥n Ä‘á» (MSA failed)

---

### PART 5C: Python Hands-on (1.5 hours) - CORE TASK

**Task 1: Simulate Gage R&R Study**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Simulate Gage R&R Study
# 3 operators Ã— 5 parts Ã— 3 replicates = 45 measurements

np.random.seed(42)

# True values of parts
true_parts = np.array([10.0, 10.5, 9.5, 10.2, 9.8])

# Create measurement data
data = []
operators = ['Operator_A', 'Operator_B', 'Operator_C']
parts = ['Part_1', 'Part_2', 'Part_3', 'Part_4', 'Part_5']

for op_idx, operator in enumerate(operators):
    for part_idx, part in enumerate(parts):
        true_value = true_parts[part_idx]
        
        # Operator bias (reproducibility)
        operator_bias = np.random.normal(0, 0.1, 1)[0]
        
        for replicate in range(1, 4):
            # Measurement error (repeatability)
            measurement_error = np.random.normal(0, 0.15, 1)[0]
            measurement = true_value + operator_bias + measurement_error
            
            data.append({
                'Operator': operator,
                'Part': part,
                'Replicate': replicate,
                'Measurement': measurement
            })

df_gage = pd.DataFrame(data)
print("GAGE R&R STUDY DATA")
print("=" * 60)
print(f"Total measurements: {len(df_gage)}")
print(f"\nFirst 15 measurements:")
print(df_gage.head(15))
```

**Task 2: Calculate Gage R&R Statistics**

```python
# Calculate Gage R&R components
print("\n" + "=" * 60)
print("GAGE R&R ANALYSIS")
print("=" * 60)

# 1. Total Variation
overall_mean = df_gage['Measurement'].mean()
overall_std = df_gage['Measurement'].std()
print(f"\nOverall Mean: {overall_mean:.3f}")
print(f"Overall Std Dev: {overall_std:.3f}")

# 2. Repeatability (Within operator variation)
repeatability_data = []
for operator in operators:
    op_data = df_gage[df_gage['Operator'] == operator]
    within_op_std = op_data.groupby('Part')['Measurement'].std().mean()
    repeatability_data.append({
        'Operator': operator,
        'Within_Std': within_op_std
    })
df_repeatability = pd.DataFrame(repeatability_data)
repeatability = df_repeatability['Within_Std'].mean()
print(f"\nRepeatability (Avg Within-Operator Std): {repeatability:.4f}")

# 3. Reproducibility (Between operator variation)
operator_means = df_gage.groupby('Operator')['Measurement'].mean()
reproducibility = operator_means.std()
print(f"Reproducibility (Between-Operator Std): {reproducibility:.4f}")

# 4. Total Gage R&R
gage_rr_variation = np.sqrt(repeatability**2 + reproducibility**2)
print(f"\nTotal Gage R&R (Combined Variation): {gage_rr_variation:.4f}")

# 5. Gage R&R as % of Tolerance
# Assume tolerance = USL - LSL = 11 - 9 = 2
tolerance = 2.0
gage_rr_percent = (gage_rr_variation / tolerance) * 100
print(f"\nGage R&R % of Tolerance: {gage_rr_percent:.2f}%")

# Acceptance Decision
if gage_rr_percent < 10:
    verdict = "âœ“ EXCELLENT - Measurement system is adequate"
elif gage_rr_percent < 30:
    verdict = "âš  ACCEPTABLE - Measurement system is marginal"
else:
    verdict = "âœ— NOT ACCEPTABLE - Improve measurement system"

print(f"\nVERDICT: {verdict}")
```

**Task 3: Visualize Gage R&R**

```python
# Plot 1: Measurements by Operator and Part
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1a: By Operator
ax1 = axes[0]
for operator in operators:
    op_data = df_gage[df_gage['Operator'] == operator]['Measurement']
    ax1.scatter([operator] * len(op_data), op_data, alpha=0.6, s=80)
ax1.axhline(overall_mean, color='red', linestyle='--', linewidth=2, label='Overall Mean')
ax1.set_ylabel('Measurement')
ax1.set_title('Measurements by Operator (Reproducibility)')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 1b: By Part
ax2 = axes[1]
for part_idx, part in enumerate(parts):
    part_data = df_gage[df_gage['Part'] == part]['Measurement']
    ax2.scatter([part_idx] * len(part_data), part_data, alpha=0.6, s=80)
ax2.axhline(overall_mean, color='red', linestyle='--', linewidth=2, label='Overall Mean')
ax2.set_xticks(range(len(parts)))
ax2.set_xticklabels(parts, rotation=45)
ax2.set_ylabel('Measurement')
ax2.set_title('Measurements by Part')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Plot 2: Interaction Plot (Reproducibility visualization)
plt.figure(figsize=(10, 6))
for operator in operators:
    op_data = df_gage[df_gage['Operator'] == operator].groupby('Part')['Measurement'].mean()
    plt.plot(parts, op_data.values, marker='o', label=operator, linewidth=2)

plt.xlabel('Part')
plt.ylabel('Average Measurement')
plt.title('Interaction Plot: Operator Ã— Part (Reproducibility)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

**Task 4: Gage R&R Report**

```python
# Create comprehensive Gage R&R report
report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          GAGE R&R STUDY REPORT                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MEASUREMENT SYSTEM: Part Dimension Measurement
DATE: {pd.Timestamp.now().strftime('%Y-%m-%d')}
TOLERANCE: 2.0 mm (9 mm - 11 mm)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EXECUTIVE SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Gage R&R %: {gage_rr_percent:.2f}%
Status: {verdict}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DETAILED ANALYSIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. REPEATABILITY (Equipment Variation)
   Average Within-Operator Std Dev: {repeatability:.4f} mm
   Interpretation: Equipment variation when same person 
                   measures same part multiple times

2. REPRODUCIBILITY (Operator Variation)
   Between-Operator Std Dev: {reproducibility:.4f} mm
   Interpretation: Variation across different operators

3. TOTAL GAGE R&R
   Combined Variation: {gage_rr_variation:.4f} mm
   % of Tolerance: {gage_rr_percent:.2f}%

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPERATOR ANALYSIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

for operator in operators:
    op_data = df_gage[df_gage['Operator'] == operator]['Measurement']
    report += f"\n{operator}:"
    report += f"\n  Mean: {op_data.mean():.3f} mm"
    report += f"\n  Std Dev: {op_data.std():.3f} mm"
    report += f"\n  Range: {op_data.max() - op_data.min():.3f} mm\n"

report += f"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RECOMMENDATIONS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

if gage_rr_percent < 10:
    report += "âœ“ Proceed with process capability analysis\n"
    report += "âœ“ Measurement system is adequate for decision-making\n"
elif gage_rr_percent < 30:
    report += "âš  Monitor measurement system performance\n"
    report += "âš  Consider retraining operators\n"
    report += "âš  Increase sample size for analysis\n"
else:
    report += "âœ— STOP: Improve measurement system before proceeding\n"
    report += "âœ— Options: Retrain operators, calibrate equipment, use better tools\n"

print(report)

# Save report
with open('gage_rr_report.txt', 'w') as f:
    f.write(report)
print("\n" + "=" * 60)
print("Report saved to 'gage_rr_report.txt'")
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 4: MSA & Gage R&R (Chi Tiáº¿t)
ğŸ“˜ FILE 2 [171] - Quick Reference: MSA Formulas
ğŸ“˜ FILE 3 [172] - Example (Náº¿u cÃ³)
ğŸ“˜ FILE 5 [174] - FAQ: Why MSA matters
```

---

### PART 5D: Summary Checklist â­ IMPORTANT
- [ ] Hiá»ƒu Accuracy vs Precision
- [ ] Hiá»ƒu Repeatability vs Reproducibility
- [ ] Cháº¡y Ä‘Æ°á»£c Gage R&R calculation
- [ ] Diá»…n giáº£i Ä‘Æ°á»£c Gage R&R %
- [ ] Biáº¿t khi nÃ o accept/reject há»‡ thá»‘ng Ä‘o
- [ ] Táº¡o Ä‘Æ°á»£c Gage R&R report

**âš ï¸ KEY POINT:** Náº¿u Gage R&R > 30%, hÃ£y STOP vÃ  cáº£i tiáº¿n há»‡ thá»‘ng Ä‘o. KhÃ´ng pháº£i tiáº¿p tá»¥c phÃ¢n tÃ­ch!

---

---

## NGÃ€Y 6: Process Capability (NÄƒng Lá»±c QuÃ¡ TrÃ¬nh)
### Day 6: Cp, Cpk, Pp, Ppk - "Quy TrÃ¬nh CÃ³ ÄÃ¡p á»¨ng Spec KhÃ´ng?"

**Duration:** 5-6 hours
**Objective:** TÃ­nh & giáº£i thÃ­ch Cpk, váº½ biá»ƒu Ä‘á»“ phÃ¢n phá»‘i chuáº©n

---

### PART 6A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Normal Distribution & Capability

**Setup:**
```
LSL (Lower Spec Limit) = 9mm
Target = 10mm
USL (Upper Spec Limit) = 11mm
Total Tolerance = 2mm

Î¼ (Mean) = ?
Ïƒ (Std Dev) = ?

CÃ¢u há»i: Quy trÃ¬nh cÃ³ sáº£n xuáº¥t Ä‘Æ°á»£c theo spec khÃ´ng?
```

**Key Metrics:**

| Metric | Formula | Ã NghÄ©a |
|--------|---------|---------|
| **Cp** | (USL - LSL) / (6Ïƒ) | Tiá»m nÄƒng (náº¿u centered) |
| **Cpk** | Min[(USL - Î¼)/(3Ïƒ), (Î¼ - LSL)/(3Ïƒ)] | Kháº£ nÄƒng thá»±c táº¿ |
| **Pp** | (USL - LSL) / (6Ïƒ) * [Long-term] | Performance (tÆ°Æ¡ng tá»± Cp nhÆ°ng dÃ¹ng dá»¯ liá»‡u thá»±c) |
| **Ppk** | Min[(USL - Î¼)/(3Ïƒ), (Î¼ - LSL)/(3Ïƒ)] * [Long-term] | Performance thá»±c táº¿ |

**Differences:**
```
Cp/Cpk = DÃ¹ng short-term data (1-2 tuáº§n, cÃ¹ng operator, cÃ¹ng machine)
         â†’ Xem quÃ¡ trÃ¬nh "cÃ³ thá»ƒ" lÃ m tá»‘t bao nhiÃªu

Pp/Ppk = DÃ¹ng long-term data (1-3 thÃ¡ng, toÃ n bá»™ operator, toÃ n bá»™ shift)
         â†’ Xem quÃ¡ trÃ¬nh "thá»±c táº¿" Ä‘ang lÃ m tá»‘t bao nhiÃªu

â†’ Ppk < Cpk = QuÃ¡ trÃ¬nh cÃ³ váº¥n Ä‘á» (operator, shift, time-of-day effect)
```

#### 2. Interpreting Cpk

```
Cpk â‰¥ 1.67  â†’ Excellent (6 Sigma)
Cpk â‰¥ 1.33  â†’ Acceptable (4 Sigma) â† Industry Standard
Cpk â‰¥ 1.0   â†’ Minimum capability (3 Sigma)
Cpk < 1.0   â†’ Not capable â† Need improvement

Example:
Cpk = 0.67  â†’ 4.5% defect rate (Very bad)
Cpk = 1.0   â†’ 0.3% defect rate (Acceptable)
Cpk = 1.33  â†’ 0.006% defect rate (Good)
Cpk = 2.0   â†’ < 0.001% defect rate (Excellent)
```

#### 3. Six Sigma Shift Rule

```
âš ï¸ IMPORTANT CONCEPT:

Long-term capability shifts 1.5 sigma from short-term
â†’ Ppk â‰ˆ Cpk - 0.5

Example:
Short-term: Cpk = 1.67 (6 Sigma short-term)
Long-term: Ppk = 1.17 (5 Sigma long-term due to 1.5Ïƒ shift)

This 1.5Ïƒ shift accounts for:
- Centering drift over time
- Machine wear
- Environmental changes
- Multiple operators
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - MEASURE Phase: Process Capability
ğŸ“˜ ISCCA Materials - Capability Analysis
ğŸ“˜ FILE 1 [170] - SECTION 4: Capability Metrics
```

---

### PART 6B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
TÃ´i cÃ³ data tá»« quy trÃ¬nh sáº£n xuáº¥t API response time:
- 200 measurements (long-term data)
- Mean = 105 ms
- Std Dev = 8 ms
- LSL = 80 ms (minimum acceptable)
- USL = 120 ms (maximum acceptable)

Há»i:
1. TÃ­nh Ppk (long-term capability index)
2. Quy trÃ¬nh nÃ y cÃ³ "qualified" khÃ´ng? (standard: Ppk â‰¥ 1.33)
3. Náº¿u khÃ´ng qualified, Ä‘iá»u gÃ¬ sáº½ xáº£y ra?
4. LÃ m sao Ä‘á»ƒ improve tá»« Ppk = ? lÃªn Ppk = 1.33?
```

**Expected Outcome:**
- TÃ­nh Ä‘Æ°á»£c Cpk/Ppk
- Biáº¿t cÃ¡ch giáº£i thÃ­ch káº¿t quáº£
- Hiá»ƒu hÃ nh Ä‘á»™ng cáº§n thiáº¿t

---

### PART 6C: Python Hands-on (1.5 hours)

**Task 1: Calculate and Visualize Capability**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Generate process data
np.random.seed(42)
data = np.random.normal(loc=105, scale=8, size=200)  # 200 measurements

# Specifications
LSL = 80
Target = 100
USL = 120

# Calculate statistics
n = len(data)
mean = np.mean(data)
std_dev = np.std(data, ddof=1)  # Sample std dev

print("=" * 60)
print("PROCESS CAPABILITY ANALYSIS")
print("=" * 60)
print(f"\nData Summary:")
print(f"  Sample size: {n}")
print(f"  Mean (Î¼): {mean:.2f}")
print(f"  Std Dev (Ïƒ): {std_dev:.2f}")
print(f"  Min: {data.min():.2f}")
print(f"  Max: {data.max():.2f}")

# Calculate capability indices
Pp = (USL - LSL) / (6 * std_dev)
Ppu = (USL - mean) / (3 * std_dev)  # Upper
Ppl = (mean - LSL) / (3 * std_dev)  # Lower
Ppk = min(Ppu, Ppl)

print(f"\nCapability Indices (Pp, Ppk):")
print(f"  Pp (Potential): {Pp:.4f}")
print(f"  Ppu (Upper): {Ppu:.4f}")
print(f"  Ppl (Lower): {Ppl:.4f}")
print(f"  Ppk (Actual): {Ppk:.4f}")

# Assessment
print(f"\nAssessment:")
if Ppk >= 1.67:
    assessment = "âœ“âœ“ EXCELLENT (6 Sigma)"
elif Ppk >= 1.33:
    assessment = "âœ“ ACCEPTABLE (4 Sigma)"
elif Ppk >= 1.0:
    assessment = "âš  MARGINAL (3 Sigma)"
else:
    assessment = "âœ— NOT CAPABLE"

print(f"  {assessment}")

# Calculate defect rate
defect_rate = 2 * (1 - norm.cdf(USL, mean, std_dev))  # % above USL
defect_rate += 2 * norm.cdf(LSL, mean, std_dev)  # % below LSL
print(f"  Expected defect rate: {defect_rate:.4f}%")

# Plot capability visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Histogram with normal curve
ax1 = axes[0]
ax1.hist(data, bins=30, edgecolor='black', alpha=0.7, density=True, label='Data')

# Overlay normal distribution
x = np.linspace(data.min(), data.max(), 100)
ax1.plot(x, norm.pdf(x, mean, std_dev), 'r-', linewidth=2, label='Normal Distribution')

# Add specification limits
ax1.axvline(LSL, color='red', linestyle='--', linewidth=2, label=f'LSL ({LSL})')
ax1.axvline(USL, color='green', linestyle='--', linewidth=2, label=f'USL ({USL})')
ax1.axvline(Target, color='orange', linestyle=':', linewidth=2, label=f'Target ({Target})')
ax1.axvline(mean, color='blue', linestyle='-', linewidth=2, label=f'Mean ({mean:.2f})')

ax1.set_xlabel('Measurement Value')
ax1.set_ylabel('Density')
ax1.set_title('Process Capability: Histogram + Normal Distribution')
ax1.legend(loc='upper right')
ax1.grid(True, alpha=0.3)

# Plot 2: Capability summary (visual)
ax2 = axes[1]

# Create a visual representation
indices = ['Pp', 'Ppk', 'Target']
values = [Pp, Ppk, 1.33]
colors = ['blue', 'green' if Ppk >= 1.33 else 'red', 'orange']

bars = ax2.barh(indices, values, color=colors, alpha=0.7)
ax2.axvline(1.33, color='red', linestyle='--', linewidth=2, label='Acceptable (1.33)')
ax2.axvline(1.67, color='green', linestyle='--', linewidth=2, label='Excellent (1.67)')
ax2.set_xlabel('Capability Index')
ax2.set_title('Capability Index Comparison')
ax2.legend()
ax2.grid(True, alpha=0.3, axis='x')

# Add value labels on bars
for bar, value in zip(bars, values):
    ax2.text(value, bar.get_y() + bar.get_height()/2, f' {value:.2f}',
            va='center', fontweight='bold')

plt.tight_layout()
plt.show()
```

**Task 2: Simulation - Impact of Centering**

```python
# Show impact of centering on Cpk
print("\n" + "=" * 60)
print("IMPACT OF CENTERING ON CAPABILITY")
print("=" * 60)

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

scenarios = [
    {'name': 'Well Centered', 'mean': 100, 'std': 8},
    {'name': 'Shifted High', 'mean': 110, 'std': 8},
    {'name': 'Shifted Low', 'mean': 90, 'std': 8},
    {'name': 'High Variation', 'mean': 100, 'std': 12}
]

for idx, (ax, scenario) in enumerate(zip(axes.flat, scenarios)):
    mu = scenario['mean']
    sigma = scenario['std']
    
    # Calculate Ppk
    Ppu = (USL - mu) / (3 * sigma)
    Ppl = (mu - LSL) / (3 * sigma)
    Ppk = min(Ppu, Ppl)
    
    # Plot
    x = np.linspace(60, 140, 200)
    ax.plot(x, norm.pdf(x, mu, sigma) * 0.5, 'b-', linewidth=2)
    ax.fill_between(x, norm.pdf(x, mu, sigma) * 0.5, alpha=0.3)
    
    # Spec limits
    ax.axvline(LSL, color='red', linestyle='--', linewidth=2)
    ax.axvline(USL, color='green', linestyle='--', linewidth=2)
    ax.axvline(mu, color='blue', linestyle='-', linewidth=2)
    
    ax.set_title(f"{scenario['name']}\nPpk = {Ppk:.2f}")
    ax.set_xlabel('Measurement')
    ax.set_ylabel('Frequency')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(60, 140)

plt.suptitle('Impact of Mean Shift & Variation on Ppk', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()
```

**Task 3: Improvement Plan**

```python
# Create improvement targets
print("\n" + "=" * 60)
print("IMPROVEMENT PLAN TO ACHIEVE Ppk â‰¥ 1.33")
print("=" * 60)

current_ppk = Ppk
target_ppk = 1.33

print(f"\nCurrent State: Ppk = {current_ppk:.2f}")
print(f"Target State: Ppk = {target_ppk:.2f}")

if current_ppk < target_ppk:
    print("\nâš ï¸ Process NOT CAPABLE")
    
    # Option 1: Reduce variation
    target_std = (USL - LSL) / (6 * target_ppk)
    reduction = ((std_dev - target_std) / std_dev) * 100
    
    print(f"\nOption 1: Reduce Variation (Keep mean at {mean:.2f})")
    print(f"  Current Std Dev: {std_dev:.2f}")
    print(f"  Target Std Dev: {target_std:.2f}")
    print(f"  Required reduction: {reduction:.1f}%")
    print(f"  How: Better equipment, training, material control")
    
    # Option 2: Shift mean to center
    target_mean = (LSL + USL) / 2
    print(f"\nOption 2: Recenter Process (Keep Std Dev at {std_dev:.2f})")
    print(f"  Current Mean: {mean:.2f}")
    print(f"  Target Mean: {target_mean:.2f}")
    print(f"  Required shift: {abs(mean - target_mean):.2f}")
    print(f"  How: Adjust machine setpoint, calibration")
    
    # Option 3: Combined
    combined_std = 6.5
    combined_mean = 100
    combined_ppk = min(
        (USL - combined_mean) / (3 * combined_std),
        (combined_mean - LSL) / (3 * combined_std)
    )
    print(f"\nOption 3: Combined Approach")
    print(f"  Reduce Std Dev to: {combined_std:.2f} ({((std_dev - combined_std)/std_dev)*100:.1f}% reduction)")
    print(f"  Shift mean to: {combined_mean:.2f}")
    print(f"  Resulting Ppk: {combined_ppk:.2f} âœ“")

else:
    print(f"\nâœ“ Process IS CAPABLE (Ppk = {current_ppk:.2f} â‰¥ {target_ppk:.2f})")
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 4: Capability Metrics
ğŸ“˜ FILE 2 [171] - Six Sigma Formulas & Thresholds
ğŸ“˜ FILE 3 [172] - Example: Capability Calculation
ğŸ“˜ FILE 5 [174] - FAQ: Interpreting Cpk & Ppk
```

---

### PART 6D: Summary Checklist
- [ ] TÃ­nh Ä‘Æ°á»£c Cp, Cpk, Pp, Ppk
- [ ] Biáº¿t sá»± khÃ¡c biá»‡t giá»¯a Cp vs Cpk, Pp vs Ppk
- [ ] Váº½ Ä‘Æ°á»£c histogram vá»›i spec limits
- [ ] Diá»…n giáº£i Ä‘Æ°á»£c káº¿t quáº£ Ppk
- [ ] Láº­p Ä‘Æ°á»£c improvement plan tá»« Ppk

**â­ Kiáº¿n Thá»©c Quan Trá»ng:**
```
Cpk = 1.33 lÃ  "passing grade" cho háº§u háº¿t ngÃ nh
Náº¿u Cpk < 1.33 â†’ KhÃ´ng nÃªn báº¯t Ä‘áº§u ANALYZE phase
Pháº£i improve há»‡ thá»‘ng measure/quy trÃ¬nh trÆ°á»›c
```

---

---

# GIAI ÄOáº N 3: ANALYZE (PHÃ‚N TÃCH & TÃŒM NGUYÃŠN NHÃ‚N)
## NgÃ y 7-8: Kiá»ƒm Äá»‹nh Thá»‘ng KÃª & Root Cause

---

## NGÃ€Y 7: Hypothesis Testing - Pháº§n 1
### Day 7: t-test, ANOVA - "CÃ³ Sá»± KhÃ¡c Biá»‡t Tháº­t KhÃ´ng?"

**Duration:** 5-6 hours
**Objective:** Hiá»ƒu p-value, cháº¡y t-test & ANOVA, giáº£i thÃ­ch káº¿t quáº£

---

### PART 7A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Hypothesis Testing Basics

**TÃ¬nh Huá»‘ng:**
```
Claim: "Ca chiá»u lá»—i nhiá»u hÆ¡n ca sÃ¡ng"

Data:
  Morning: 5, 6, 4, 8, 9        (mean = 6.4)
  Evening: 15, 16, 14, 17, 15   (mean = 15.4)

CÃ¢u há»i: Sá»± khÃ¡c biá»‡t 6.4 vs 15.4 lÃ  tháº­t hay chá»‰ do may rá»§i?
```

**Hypothesis Formulation:**

```
H0 (Null): KhÃ´ng cÃ³ sá»± khÃ¡c biá»‡t (mean_morning = mean_evening)
H1 (Alternative): CÃ³ sá»± khÃ¡c biá»‡t (mean_morning â‰  mean_evening)

TÆ° duy:
- Giáº£ sá»­ H0 Ä‘Ãºng (khÃ´ng cÃ³ khÃ¡c biá»‡t)
- Náº¿u data mÃ  chÃºng ta tháº¥y quÃ¡ báº¥t thÆ°á»ng â†’ BÃ¡c bá» H0
- NgÆ°á»¡ng "báº¥t thÆ°á»ng" = p-value < 0.05 (5% risk)
```

#### 2. P-Value Explained (KhÃ´ng Pháº£i XÃ¡c Suáº¥t)

```
âŒ WRONG: "P-value = 0.03 = 3% kháº£ nÄƒng H0 Ä‘Ãºng"
âœ… RIGHT: "P-value = 0.03 = Náº¿u H0 Ä‘Ãºng, xÃ¡c suáº¥t tháº¥y 
           dá»¯ liá»‡u báº¥t thÆ°á»ng nhÆ° váº­y chá»‰ 3%"

Analogy: Báº¡n tung Ä‘á»“ng xu 10 láº§n, Ä‘Æ°á»£c 9 máº·t ngá»­a
  H0: Äá»“ng xu cÃ´ng báº±ng (p = 0.5)
  P-value = 0.002 = Náº¿u cÃ´ng báº±ng, xÃ¡c suáº¥t 9+ ngá»­a chá»‰ 0.2%
  Káº¿t luáº­n: Äá»“ng xu khÃ´ng cÃ´ng báº±ng â†’ BÃ¡c bá» H0
```

**Decision Rule:**
```
p-value < 0.05  â†’ BÃ¡c bá» H0 (CÃ³ sá»± khÃ¡c biá»‡t Ã½ nghÄ©a) âœ“
p-value â‰¥ 0.05  â†’ KhÃ´ng bÃ¡c bá» H0 (KhÃ´ng Ä‘á»§ báº±ng chá»©ng) âœ—
```

#### 3. Choosing the Right Test

**Decision Tree:**
```
Data Normal?
â”œâ”€ YES â†’ Parametric Test (t-test, ANOVA)
â”‚        (Giáº£ sá»­ data tuÃ¢n theo normal distribution)
â”‚
â””â”€ NO  â†’ Non-parametric Test (Mann-Whitney U, Kruskal-Wallis)
         (KhÃ´ng giáº£ sá»­ gÃ¬ vá» distribution)

Compare how many groups?
â”œâ”€ 2 groups
â”‚  â”œâ”€ Normal   â†’ Independent t-test (hoáº·c Paired t-test)
â”‚  â””â”€ Not normal â†’ Mann-Whitney U test
â”‚
â””â”€ 3+ groups
   â”œâ”€ Normal   â†’ ANOVA (Analysis of Variance)
   â””â”€ Not normal â†’ Kruskal-Wallis test
```

#### 4. T-Test Types

**A. Independent (Two-Sample) t-test**
```
Purpose: So sÃ¡nh mean cá»§a 2 Ä‘á»™c láº­p nhÃ³m
VÃ­ dá»¥: Morning shift vs Evening shift
H0: Î¼_morning = Î¼_evening
```

**B. Paired t-test**
```
Purpose: So sÃ¡nh cáº·p data (trÆ°á»›c-sau)
VÃ­ dá»¥: Developer's speed trÆ°á»›c vs sau training
H0: Î¼_before = Î¼_after
```

**C. One-Sample t-test**
```
Purpose: So sÃ¡nh vá»›i má»™t giÃ¡ trá»‹ (target)
VÃ­ dá»¥: API response time vs SLA target (100ms)
H0: Î¼ = 100
```

#### 5. ANOVA (Analysis of Variance)

**Purpose:** So sÃ¡nh mean cá»§a 3+ nhÃ³m

```
ANOVA: F-test
H0: Î¼1 = Î¼2 = Î¼3 = ... (all equal)
H1: At least one Î¼ different

Output: F-statistic & p-value

Náº¿u p < 0.05: CÃ³ Ã­t nháº¥t má»™t nhÃ³m khÃ¡c â†’ Cáº§n post-hoc test
(VÃ­ dá»¥: pairwise t-test Ä‘á»ƒ tÃ¬m cáº·p nÃ o khÃ¡c)
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - ANALYZE Phase: Hypothesis Testing
ğŸ“˜ ISCCA Materials - Statistical Tests
ğŸ“˜ FILE 1 [170] - SECTION 5: Hypothesis Testing
ğŸ“˜ FILE 2 [171] - Statistical Tests Decision Tree
```

---

### PART 7B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
Báº¡n lÃ  Data Analyst cho má»™t e-commerce company.

TÃ¬nh huá»‘ng: "Trang checkout má»›i cÃ³ conversion rate cao hÆ¡n trang cÅ©"

Data (2 tuáº§n):
  Old page: 150 visitors â†’ 12 purchases (8% conversion)
  New page: 148 visitors â†’ 18 purchases (12.2% conversion)

Há»i:
1. P-value lÃ  gÃ¬? KhÃ´ng pháº£i xÃ¡c suáº¥t pháº£i khÃ´ng?
2. NÃªn dÃ¹ng kiá»ƒm Ä‘á»‹nh nÃ o? (t-test hay Chi-square)
3. Náº¿u p-value = 0.08, báº¡n káº¿t luáº­n gÃ¬?
4. Náº¿u p-value = 0.02, báº¡n káº¿t luáº­n gÃ¬?

Báº¡n giáº£i thÃ­ch:
- H0 & H1
- Decision rule
- Practical implication
```

**Expected Outcome:**
- Hiá»ƒu p-value khÃ´ng pháº£i xÃ¡c suáº¥t mÃ  lÃ  "báº¥t thÆ°á»ng measure"
- Biáº¿t chá»n kiá»ƒm Ä‘á»‹nh phÃ¹ há»£p
- Diá»…n giáº£i káº¿t quáº£ Ä‘Ãºng

---

### PART 7C: Python Hands-on (1.5 hours)

**Task 1: Check Normality First**

```python
from scipy import stats
import numpy as np
import pandas as pd

# Data
morning_shift = np.array([5, 6, 4, 8, 9])
evening_shift = np.array([15, 16, 14, 17, 15])

print("=" * 60)
print("STEP 1: CHECK NORMALITY (Shapiro-Wilk Test)")
print("=" * 60)

# Shapiro-Wilk test
stat_morning, p_norm_morning = stats.shapiro(morning_shift)
stat_evening, p_norm_evening = stats.shapiro(evening_shift)

print(f"\nMorning Shift:")
print(f"  Test Statistic: {stat_morning:.4f}")
print(f"  P-value: {p_norm_morning:.4f}")
print(f"  Normal? {'YES âœ“' if p_norm_morning > 0.05 else 'NO âœ—'}")

print(f"\nEvening Shift:")
print(f"  Test Statistic: {stat_evening:.4f}")
print(f"  P-value: {p_norm_evening:.4f}")
print(f"  Normal? {'YES âœ“' if p_norm_evening > 0.05 else 'NO âœ—'}")

# Decision
both_normal = (p_norm_morning > 0.05) and (p_norm_evening > 0.05)
print(f"\nâ†’ Use parametric test (t-test)? {both_normal}")
if not both_normal:
    print(f"â†’ Use non-parametric test (Mann-Whitney U)? {not both_normal}")
```

**Task 2: Independent T-Test**

```python
print("\n" + "=" * 60)
print("STEP 2: INDEPENDENT T-TEST (or Mann-Whitney U)")
print("=" * 60)

if both_normal:
    # Use t-test
    t_stat, p_value = stats.ttest_ind(morning_shift, evening_shift)
    test_name = "Independent t-test"
else:
    # Use Mann-Whitney U
    t_stat, p_value = stats.mannwhitneyu(morning_shift, evening_shift)
    test_name = "Mann-Whitney U test"

print(f"\nTest: {test_name}")
print(f"Morning mean: {morning_shift.mean():.2f}")
print(f"Evening mean: {evening_shift.mean():.2f}")
print(f"Difference: {evening_shift.mean() - morning_shift.mean():.2f}")

print(f"\nTest Results:")
print(f"  Test Statistic: {t_stat:.4f}")
print(f"  P-value: {p_value:.6f}")

# Decision
alpha = 0.05
print(f"\n  H0 (Null Hypothesis): mean_morning = mean_evening")
print(f"  H1 (Alternative): mean_morning â‰  mean_evening")
print(f"  Significance level (Î±): {alpha}")

if p_value < alpha:
    print(f"\n  âœ“ P-value ({p_value:.6f}) < Î± ({alpha})")
    print(f"  â†’ REJECT H0")
    print(f"  â†’ CONCLUSION: There IS a significant difference")
    print(f"  â†’ Evening shift has significantly MORE defects")
else:
    print(f"\n  âœ— P-value ({p_value:.6f}) â‰¥ Î± ({alpha})")
    print(f"  â†’ FAIL TO REJECT H0")
    print(f"  â†’ CONCLUSION: No significant difference found")
    print(f"  â†’ Difference might be due to chance")
```

**Task 3: ANOVA (3+ Groups)**

```python
print("\n" + "=" * 60)
print("STEP 3: ANOVA (3+ Groups)")
print("=" * 60)

# Add night shift
night_shift = np.array([12, 13, 11, 14, 12])

# ANOVA
f_stat, p_anova = stats.f_oneway(morning_shift, evening_shift, night_shift)

print(f"\nComparing 3 Shifts:")
print(f"  Morning mean: {morning_shift.mean():.2f}")
print(f"  Evening mean: {evening_shift.mean():.2f}")
print(f"  Night mean: {night_shift.mean():.2f}")

print(f"\nANOVA Results:")
print(f"  F-Statistic: {f_stat:.4f}")
print(f"  P-value: {p_anova:.6f}")

if p_anova < 0.05:
    print(f"\n  âœ“ REJECT H0 (p = {p_anova:.6f} < 0.05)")
    print(f"  â†’ At least ONE shift has significantly different defect rate")
    
    # Post-hoc: pairwise comparisons
    print(f"\n  POST-HOC: Pairwise t-tests")
    
    pairs = [
        ("Morning", "Evening", morning_shift, evening_shift),
        ("Morning", "Night", morning_shift, night_shift),
        ("Evening", "Night", evening_shift, night_shift)
    ]
    
    for name1, name2, data1, data2 in pairs:
        t_stat_pair, p_pair = stats.ttest_ind(data1, data2)
        sig = "âœ“" if p_pair < 0.05 else "âœ—"
        print(f"    {sig} {name1} vs {name2}: p = {p_pair:.4f}")

else:
    print(f"\n  âœ— FAIL TO REJECT H0 (p = {p_anova:.6f} â‰¥ 0.05)")
    print(f"  â†’ No significant difference among shifts")
```

**Task 4: Visualization**

```python
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Box plot
ax1 = axes[0]
data_for_plot = [morning_shift, evening_shift, night_shift]
ax1.boxplot(data_for_plot, labels=['Morning', 'Evening', 'Night'])
ax1.set_ylabel('Number of Defects')
ax1.set_title('Distribution of Defects by Shift')
ax1.grid(True, alpha=0.3)

# Plot 2: Comparison with error bars
ax2 = axes[1]
shifts = ['Morning', 'Evening', 'Night']
means = [morning_shift.mean(), evening_shift.mean(), night_shift.mean()]
stds = [morning_shift.std(), evening_shift.std(), night_shift.std()]

x_pos = np.arange(len(shifts))
ax2.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7)
ax2.set_xticks(x_pos)
ax2.set_xticklabels(shifts)
ax2.set_ylabel('Average Defects')
ax2.set_title('Mean Â± Std Dev by Shift')
ax2.grid(True, alpha=0.3, axis='y')

# Add value labels
for i, (mean, std) in enumerate(zip(means, stds)):
    ax2.text(i, mean + std + 0.5, f'{mean:.1f}', ha='center', fontweight='bold')

plt.tight_layout()
plt.show()
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 5: Hypothesis Testing (Chi Tiáº¿t)
ğŸ“˜ FILE 2 [171] - Statistical Tests Decision Tree
ğŸ“˜ FILE 3 [172] - Example 3: T-Test & ANOVA
ğŸ“˜ FILE 5 [174] - FAQ: Understanding P-value
```

---

### PART 7D: Summary Checklist
- [ ] Hiá»ƒu p-value lÃ  gÃ¬ (khÃ´ng pháº£i xÃ¡c suáº¥t H0 Ä‘Ãºng)
- [ ] Kiá»ƒm tra Normality báº±ng Shapiro-Wilk
- [ ] Cháº¡y Ä‘Æ°á»£c t-test & ANOVA
- [ ] Diá»…n giáº£i káº¿t quáº£ (p-value < 0.05 = reject H0)
- [ ] Thá»±c hiá»‡n post-hoc test (pairwise) khi cáº§n

---

---

## NGÃ€Y 8: Correlation, Regression & Root Cause Analysis
### Day 8: Má»‘i Quan Há»‡ Giá»¯a X & Y, Fishbone, 5 Whys

**Duration:** 5-6 hours
**Objective:** TÃ¬m biáº¿n X áº£nh hÆ°á»Ÿng, váº½ Fishbone, dÃ¹ng 5 Whys

---

### PART 8A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Correlation (TÆ°Æ¡ng Quan)

**Concept:**
```
X (Independent) â†’ Y (Dependent)
VÃ­ dá»¥: Temperature â†’ Defect rate

Correlation (r):
  -1 â‰¤ r â‰¤ +1

  r = +1: Perfect positive (náº¿u X â†‘ thÃ¬ Y â†‘)
  r = +0.8: Strong positive
  r = +0.5: Moderate positive
  r = 0: No correlation
  r = -0.8: Strong negative (náº¿u X â†‘ thÃ¬ Y â†“)

VÃ­ dá»¥:
  Temperature â†‘ â†’ Defect rate â†‘ (r = +0.7) â†’ Strong positive
  Code review time â†‘ â†’ Bug count â†“ (r = -0.6) â†’ Moderate negative
```

**Important:** Correlation â‰  Causation
```
âŒ "Ice cream sales & drowning deaths have high correlation"
   â†’ KhÃ´ng cÃ³ causation!
   
âœ… Root cause: Both driven by warm weather
```

#### 2. Linear Regression

```
Y = a + b*X

a = intercept (Y khi X = 0)
b = slope (Y tÄƒng bao nhiÃªu khi X tÄƒng 1 Ä‘Æ¡n vá»‹)

Example:
Defect_rate = 5 + 0.2 * Temperature

Interpretation:
  - When Temp = 0Â°C â†’ Defect rate = 5%
  - For each 1Â°C increase â†’ Defect rate increases by 0.2%
  - When Temp = 20Â°C â†’ Defect rate = 5 + 0.2*20 = 9%

RÂ² (Coefficient of Determination):
  = % of variation in Y explained by X
  Example: RÂ² = 0.64 â†’ 64% of variation explained
           â†’ 36% explained by other factors
```

#### 3. Root Cause Analysis - Fishbone Diagram

**Purpose:** TÃ¬m táº¥t cáº£ nguyÃªn nhÃ¢n tiá»m tÃ ng

**Structure (5M + 1E - Manufacturing):**
```
                        Problem
                          â†‘
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
     People          Equipment          Materials
     (äºº)              (ç‰©)                (æ)
        â”‚                 â”‚                 â”‚
     Training          Age/            Quality/
     Experience         Maintenance    Properties
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                     Methods
                    (Method)
                     Procedures
                      Training
```

**For Software:**
```
                        High Bug Rate
                          â†‘
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
      People            Tools             Code
      (Developer)    (IDE, Framework)   (Quality)
        â”‚                 â”‚                 â”‚
     Skill           Configuration      Design
     Experience      Performance        Architecture
     Motivation      Compatibility      Standards
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                      Process
                    (Development)
                   Code Review
                   Testing
```

#### 4. 5 Whys Technique

```
Problem: "API Response Time > 500ms"

Why 1? "Database query is slow"
Why 2? "No index on frequently queried column"
Why 3? "Developer didn't follow design guidelines"
Why 4? "New dev didn't receive performance training"
Why 5? "No formal onboarding process"

Root Cause: Lack of onboarding process
Action: Create developer onboarding checklist including performance best practices
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - ANALYZE Phase: Root Cause Analysis
ğŸ“˜ ISCCA Materials - Correlation, Regression, Root Cause
ğŸ“˜ FILE 1 [170] - SECTION 5: Analyze & Root Cause
```

---

### PART 8B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
Váº¥n Ä‘á»: "Tá»· lá»‡ lá»—i bug cao nháº¥t vÃ o thá»© NÄƒm & thá»© SÃ¡u"

Dá»¯ liá»‡u: Bug rate by day cá»§a week
  Mon: 2%, Tue: 2.5%, Wed: 3%, Thu: 5%, Fri: 6%, Sat: 1%, Sun: 1%

Há»i:
1. Váº½ Fishbone diagram (5 Why) Ä‘á»ƒ tÃ¬m nguyÃªn nhÃ¢n
2. CÃ¡c biáº¿n X tiá»m tÃ ng nÃ o?
   - Fatigue effect (developers má»‡t vÃ o cuá»‘i tuáº§n)?
   - Deployment schedule (deploy vÃ o cuá»‘i tuáº§n)?
   - Code review capacity (reviewer báº­n)?
   - Etc.

3. LÃ m sao kiá»ƒm chá»©ng nguyÃªn nhÃ¢n nÃ o lÃ  tháº­t?

Báº¡n hÃ£y giÃºp tÃ´i láº­p root cause analysis tá»« A-Z.
```

**Expected Outcome:**
- Váº½ Ä‘Æ°á»£c Fishbone diagram
- Ãp dá»¥ng 5 Whys
- XÃ¡c Ä‘á»‹nh X variables Ä‘á»ƒ test

---

### PART 8C: Python Hands-on (1.5 hours)

**Task 1: Correlation Analysis**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

# Generate synthetic data: Temperature vs Defect Rate
np.random.seed(42)
temperature = np.array([20, 22, 25, 28, 30, 32, 35, 28, 25, 22])
defect_rate = np.array([1.2, 1.5, 2.1, 3.5, 4.2, 5.1, 6.0, 3.8, 2.2, 1.6])

data = pd.DataFrame({
    'Temperature': temperature,
    'Defect_Rate': defect_rate
})

print("=" * 60)
print("CORRELATION ANALYSIS")
print("=" * 60)

# Calculate correlation
correlation, p_value = pearsonr(temperature, defect_rate)

print(f"\nData:")
print(data.to_string(index=False))

print(f"\nCorrelation Results:")
print(f"  Correlation coefficient (r): {correlation:.4f}")
print(f"  P-value: {p_value:.6f}")

# Interpretation
if abs(correlation) > 0.8:
    strength = "STRONG"
elif abs(correlation) > 0.5:
    strength = "MODERATE"
else:
    strength = "WEAK"

direction = "POSITIVE" if correlation > 0 else "NEGATIVE"

print(f"  Strength: {strength} {direction} correlation")

if p_value < 0.05:
    print(f"  Statistical significance: YES (p = {p_value:.4f} < 0.05)")
else:
    print(f"  Statistical significance: NO (p = {p_value:.4f} â‰¥ 0.05)")

print(f"\nInterpretation:")
print(f"  As temperature increases by 1Â°C,")
print(f"  defect rate increases by approximately {correlation/10:.3f}% (rough estimate)")
```

**Task 2: Linear Regression**

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

print("\n" + "=" * 60)
print("LINEAR REGRESSION ANALYSIS")
print("=" * 60)

# Prepare data
X = temperature.reshape(-1, 1)  # Independent variable
y = defect_rate  # Dependent variable

# Fit linear regression
model = LinearRegression()
model.fit(X, y)

# Get parameters
slope = model.coef_[0]
intercept = model.intercept_

# Calculate RÂ²
y_pred = model.predict(X)
r2 = r2_score(y, y_pred)

print(f"\nLinear Regression Equation:")
print(f"  Y = {intercept:.4f} + {slope:.4f} * X")
print(f"  Defect_Rate = {intercept:.4f} + {slope:.4f} * Temperature")

print(f"\nModel Quality:")
print(f"  RÂ² (Coefficient of Determination): {r2:.4f}")
print(f"  Interpretation: {r2*100:.1f}% of variation in defect rate")
print(f"                 is explained by temperature")
print(f"                 {(1-r2)*100:.1f}% by other factors")

print(f"\nPredictions:")
test_temps = [20, 25, 30, 35]
for temp in test_temps:
    pred_rate = intercept + slope * temp
    print(f"  At {temp}Â°C â†’ Predicted defect rate: {pred_rate:.2f}%")

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Scatter + Regression line
ax1 = axes[0]
ax1.scatter(temperature, defect_rate, s=100, alpha=0.6, label='Actual data')
ax1.plot(temperature, y_pred, 'r-', linewidth=2, label='Regression line')
ax1.set_xlabel('Temperature (Â°C)')
ax1.set_ylabel('Defect Rate (%)')
ax1.set_title(f'Linear Regression (RÂ² = {r2:.3f})')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Residuals
ax2 = axes[1]
residuals = y - y_pred
ax2.scatter(y_pred, residuals, s=100, alpha=0.6)
ax2.axhline(0, color='r', linestyle='--', linewidth=2)
ax2.set_xlabel('Fitted Values')
ax2.set_ylabel('Residuals')
ax2.set_title('Residual Plot (Check for patterns)')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**Task 3: Fishbone Diagram (Text Representation)**

```python
# Create Fishbone Diagram (Text Format)
fishbone_diagram = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           FISHBONE DIAGRAM: High Bug Rate Analysis              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                              High Bug Rate
                              (Problem)
                                   â†‘
                                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚          â”‚           â”‚           â”‚          â”‚
         People      Process      Tools     Code      Environment
          (äºº)        (éç¨‹)       (ç‰©)       (æ)      (ç’°å¢ƒ)
            â”‚          â”‚           â”‚           â”‚          â”‚
       1. Skill       1. Code      1. IDE     1. Design   1. Network
          Level         Review       Issues     Issues      Latency
       2. Experience   2. Testing  2. Framework 2. Legacy   2. Server
       3. Knowledge     Procedures  Config     3. No Code  Load
       4. Motivation   3. CI/CD     3. Version  Standards
                         Issues     Control
            â”‚          â”‚           â”‚           â”‚          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â†‘
                              (Major categories)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PRIMARY CAUSES (Likely):
  âœ“ Inadequate code review (Process)
  âœ“ Developers lack testing experience (People)
  âœ“ No code standards enforcement (Code)
  âœ“ Poor IDE/tool setup (Tools)

SECONDARY FACTORS:
  â€¢ High server load (Environment)
  â€¢ Outdated framework (Tools)
  â€¢ Fatigue effect (People - end of week)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

print(fishbone_diagram)

# Create 5 Whys analysis
five_whys = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              5 WHYS ANALYSIS: High Bug Rate                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Problem: Bug rate is 5% (target: < 1%)

Why 1: Bugs are not caught before merge?
  â†’ Insufficient code review

Why 2: Why code review is insufficient?
  â†’ Reviewers too busy, limited bandwidth

Why 3: Why limited review bandwidth?
  â†’ New team members review slowly
  â†’ Senior devs overwhelmed with other tasks

Why 4: Why new team members review slowly?
  â†’ Lack of training on code standards
  â†’ No peer review checklist

Why 5: Why no training & checklist?
  â†’ No formal onboarding process
  â†’ Team growth too fast

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ROOT CAUSE: Lack of structured onboarding & review process

CORRECTIVE ACTIONS:
  âœ“ Create developer onboarding checklist
  âœ“ Establish code review standards & checklist
  âœ“ Pair junior devs with mentors
  âœ“ Use automated linting tools

EXPECTED OUTCOME:
  â†’ Bug rate from 5% â†’ < 1% within 4 weeks

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

print(five_whys)
```

**Task 4: Saving Root Cause Analysis**

```python
# Save analysis to file
analysis_report = f"""
ROOT CAUSE ANALYSIS REPORT
Generated: {pd.Timestamp.now()}

PROBLEM STATEMENT:
  Defect rate increases with temperature
  Correlation: {correlation:.4f} (Strong positive)
  
EVIDENCE:
  â€¢ Correlation coefficient: {correlation:.4f}
  â€¢ P-value: {p_value:.6f} (Significant)
  â€¢ RÂ²: {r2:.4f} ({r2*100:.1f}% of variation explained)

REGRESSION MODEL:
  Defect_Rate = {intercept:.4f} + {slope:.4f} Ã— Temperature
  
ROOT CAUSES (from Fishbone & 5 Whys):
  1. High temperature â†’ Equipment performance degrades
  2. Thermal stress â†’ Increased error rates
  3. Inadequate cooling â†’ Control limits exceeded
  4. Maintenance schedule not aligned with climate
  5. No preventive action triggered

RECOMMENDATIONS:
  1. Improve cooling system (Equipment)
  2. Adjust process parameters for high temp (Process)
  3. Increase monitoring frequency (People)
  4. Implement temperature controls (Environment)
  
NEXT STEPS:
  â†’ Implement improvement actions
  â†’ Monitor defect rate weekly
  â†’ Re-analyze correlation after improvements
"""

with open('root_cause_analysis.txt', 'w') as f:
    f.write(analysis_report)

print("Root Cause Analysis Report saved!")
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 5: Analyze, Correlation, Regression
ğŸ“˜ FILE 2 [171] - Quick Reference: Root Cause Tools
ğŸ“˜ FILE 3 [172] - Example 6: Correlation & Regression
ğŸ“˜ FILE 5 [174] - FAQ: Correlation vs Causation
```

---

### PART 8D: Summary Checklist
- [ ] TÃ­nh Ä‘Æ°á»£c correlation coefficient
- [ ] Hiá»ƒu correlation â‰  causation
- [ ] Cháº¡y Ä‘Æ°á»£c linear regression
- [ ] Váº½ Ä‘Æ°á»£c Fishbone diagram
- [ ] Ãp dá»¥ng 5 Whys
- [ ] XÃ¡c Ä‘á»‹nh root cause & corrective actions

---

---

# GIAI ÄOáº N 4: IMPROVE & CONTROL (Cáº¢I TIáº¾N & KIá»‚M SOÃT)
## NgÃ y 9-10: DOE, Lá»±a Chá»n Giáº£i PhÃ¡p, Control Charts

---

## NGÃ€Y 9: Design of Experiments (DOE) & Solution Selection
### Day 9: DOE - TÃ¬m Cáº¥u HÃ¬nh Tá»‘i Æ¯u

**Duration:** 5-6 hours
**Objective:** Hiá»ƒu DOE, cháº¡y interaction analysis, Pugh Matrix

---

### PART 9A: LÃ½ Thuyáº¿t (2 hours)

#### 1. DOE Basics

**Purpose:** TÃ¬m cáº¥u hÃ¬nh X tá»‘i Æ°u Ä‘á»ƒ maximize/minimize Y

```
Traditional approach (Trial & Error):
  Test Config 1 â†’ Result 1
  Test Config 2 â†’ Result 2
  Test Config 3 â†’ Result 3
  ... (takes forever)

DOE approach (Factorial Design):
  Test multiple factors simultaneously
  Find interactions
  Identify optimal settings

Example: API Optimization
  Factor A: Connection pooling (Yes/No)
  Factor B: Caching (Yes/No)
  Factor C: Compression (Yes/No)
  
  2Â³ = 8 experiments needed (full factorial)
  Compare to 3Ã—3Ã—3 = 27 trials (traditional)
```

#### 2. Main Effect vs Interaction Effect

```
Main Effect:
  "Caching reduces response time by 50ms"
  
Interaction Effect:
  "Caching reduces response time by 50ms ONLY when compression is OFF"
  "With compression ON, caching has no effect"
  
â†’ This is an INTERACTION!

Why it matters:
  Can't just pick "best" factor independently
  Must consider factor combinations
```

#### 3. Pugh Matrix - Solution Selection

```
Compare multiple solution options against criteria

Criteria weights (importance):
  Cost: 30%
  Performance: 40%
  Ease of Implementation: 20%
  Maintainability: 10%

Rate solutions:
  -2: Much worse than baseline
  -1: Worse
   0: Same
  +1: Better
  +2: Much better
  
Calculate weighted scores â†’ Pick highest
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - IMPROVE Phase: DOE
ğŸ“˜ ISCCA Materials - Design of Experiments
ğŸ“˜ FILE 1 [170] - SECTION 6: Improve & DOE
```

---

### PART 9B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
TÃ´i muá»‘n optimize database query performance.

Potential improvements:
  A) Add database index
  B) Implement query caching
  C) Optimize table structure
  D) Upgrade hardware

Há»i:
1. Náº¿u chá»‰ test má»™t factor táº¡i láº§n (Aâ†’Bâ†’Câ†’D), máº¥t bao lÃ¢u?
2. DOE approach sáº½ nhÆ° tháº¿ nÃ o?
3. CÃ³ possible interactions khÃ´ng?
   - Index + Caching (synergy?)
   - Structure + Hardware (independent?)
4. DÃ¹ng Pugh Matrix so sÃ¡nh 4 options, cÃ¢n nháº¯c:
   - Cost
   - Performance improvement
   - Implementation time
   - Risk of issues
   
HÃ£y giÃºp tÃ´i design experiment & select best solution.
```

**Expected Outcome:**
- Hiá»ƒu DOE advantages vs trial-and-error
- Nháº­n biáº¿t interaction effects
- DÃ¹ng Pugh Matrix Ä‘á»ƒ quyáº¿t Ä‘á»‹nh

---

### PART 9C: Python Hands-on (1.5 hours)

**Task 1: Factorial Design & Interaction Plot**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from itertools import product

print("=" * 60)
print("2Â³ FACTORIAL DESIGN: API Optimization")
print("=" * 60)

# Factors
# A: Connection Pooling (0 = No, 1 = Yes)
# B: Caching (0 = No, 1 = Yes)
# C: Compression (0 = No, 1 = Yes)

# Response: Response Time (ms) - lower is better

# Simulated experimental results
results = {
    (0, 0, 0): 450,  # No optimization
    (1, 0, 0): 380,  # Pooling only â†’ 70ms improvement
    (0, 1, 0): 280,  # Caching only â†’ 170ms improvement
    (1, 1, 0): 150,  # Pooling + Caching â†’ 300ms improvement (synergy!)
    (0, 0, 1): 420,  # Compression only â†’ 30ms improvement
    (1, 0, 1): 340,  # Pooling + Compression â†’ 110ms improvement
    (0, 1, 1): 200,  # Caching + Compression â†’ 250ms improvement
    (1, 1, 1): 80,   # All three â†’ 370ms improvement (BEST!)
}

# Create DOE table
experiments = []
for (A, B, C), response in results.items():
    experiments.append({
        'Pooling': 'Yes' if A else 'No',
        'Caching': 'Yes' if B else 'No',
        'Compression': 'Yes' if C else 'No',
        'Response_Time_ms': response
    })

df_doe = pd.DataFrame(experiments)

print(f"\nFull Factorial Design (2Â³ = 8 experiments):")
print(df_doe.to_string(index=False))

# Calculate main effects
print("\n" + "=" * 60)
print("MAIN EFFECTS ANALYSIS")
print("=" * 60)

for factor in ['Pooling', 'Caching', 'Compression']:
    level_0 = df_doe[df_doe[factor] == 'No']['Response_Time_ms'].mean()
    level_1 = df_doe[df_doe[factor] == 'Yes']['Response_Time_ms'].mean()
    effect = level_0 - level_1
    
    print(f"\n{factor}:")
    print(f"  Without: {level_0:.1f} ms (avg)")
    print(f"  With: {level_1:.1f} ms (avg)")
    print(f"  Main Effect: {effect:.1f} ms improvement")

# Interaction effects
print("\n" + "=" * 60)
print("INTERACTION EFFECTS ANALYSIS")
print("=" * 60)

# Pooling Ã— Caching
print("\nPooling Ã— Caching Interaction:")
print("  Without Pooling:")
print(f"    No Caching: {results[(0,0,0)]:.0f} ms")
print(f"    With Caching: {results[(0,1,0)]:.0f} ms")
print(f"    Caching effect: {results[(0,0,0)] - results[(0,1,0)]:.0f} ms")

print("  With Pooling:")
print(f"    No Caching: {results[(1,0,0)]:.0f} ms")
print(f"    With Caching: {results[(1,1,0)]:.0f} ms")
print(f"    Caching effect: {results[(1,0,0)] - results[(1,1,0)]:.0f} ms")

print("\n  â†’ INTERACTION DETECTED!")
print("  â†’ Caching effect is LARGER when Pooling is used")
print("  â†’ This is SYNERGY (positive interaction)")
```

**Task 2: Interaction Plot**

```python
# Create interaction plot
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Plot 1: Pooling Ã— Caching (for each Compression level)
for compression in [0, 1]:
    comp_name = "Compression ON" if compression else "Compression OFF"
    no_pooling = []
    yes_pooling = []
    
    for caching in [0, 1]:
        no_pooling.append(results[(0, caching, compression)])
        yes_pooling.append(results[(1, caching, compression)])
    
    ax = axes[0]
    ax.plot(['No Caching', 'With Caching'], no_pooling, marker='o', 
            label=f'{comp_name} (No Pooling)', linewidth=2)
    ax.plot(['No Caching', 'With Caching'], yes_pooling, marker='s', 
            label=f'{comp_name} (With Pooling)', linewidth=2)

axes[0].set_ylabel('Response Time (ms)')
axes[0].set_title('Interaction: Pooling Ã— Caching')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Plot 2: Main effects
ax = axes[1]
factors = ['Pooling', 'Caching', 'Compression']
effects = []

for factor in factors:
    level_0 = df_doe[df_doe[factor] == 'No']['Response_Time_ms'].mean()
    level_1 = df_doe[df_doe[factor] == 'Yes']['Response_Time_ms'].mean()
    effects.append(level_0 - level_1)

bars = ax.bar(factors, effects, color=['blue', 'green', 'orange'], alpha=0.7)
ax.set_ylabel('Effect on Response Time Reduction (ms)')
ax.set_title('Main Effects Plot')
ax.grid(True, alpha=0.3, axis='y')

# Add value labels
for bar, effect in zip(bars, effects):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.0f}ms', ha='center', va='bottom', fontweight='bold')

# Plot 3: Pareto of results
ax = axes[2]
sorted_results = sorted(results.items(), key=lambda x: x[1])
configs = [f"{''.join(str(x) for x in k)}" for k, v in sorted_results]
times = [v for k, v in sorted_results]

colors_bar = ['red' if t > 200 else 'yellow' if t > 100 else 'green' for t in times]
ax.barh(range(len(configs)), times, color=colors_bar, alpha=0.7)
ax.set_yticks(range(len(configs)))
ax.set_yticklabels(configs)
ax.set_xlabel('Response Time (ms)')
ax.set_title('Pareto: Ranked Solutions (Green = Best)')
ax.grid(True, alpha=0.3, axis='x')

# Add value labels
for i, t in enumerate(times):
    ax.text(t + 5, i, f'{t}ms', va='center', fontweight='bold')

plt.tight_layout()
plt.show()

# Summary
print("\n" + "=" * 60)
print("OPTIMAL CONFIGURATION")
print("=" * 60)
best_config = min(results.items(), key=lambda x: x[1])
print(f"Best: Pooling={best_config[0][0]}, Caching={best_config[0][1]}, Compression={best_config[0][2]}")
print(f"Response Time: {best_config[1]} ms")
print(f"Improvement vs baseline: {results[(0,0,0)] - best_config[1]} ms ({((results[(0,0,0)] - best_config[1])/results[(0,0,0)]*100):.1f}%)")
```

**Task 3: Pugh Matrix for Solution Selection**

```python
print("\n" + "=" * 60)
print("PUGH MATRIX: Solution Selection")
print("=" * 60)

# Define criteria & weights
criteria_weights = {
    'Cost': 0.25,
    'Performance': 0.40,
    'Implementation Time': 0.20,
    'Risk/Complexity': 0.15
}

# Define solutions
solutions = {
    'Solution 1: Pooling Only': {
        'Cost': 1,           # +1: Low cost
        'Performance': 1,    # +1: Good improvement
        'Implementation Time': 2,  # +2: Very quick (few hours)
        'Risk/Complexity': 2  # +2: Very low risk
    },
    'Solution 2: Caching': {
        'Cost': 0,           # 0: Medium cost
        'Performance': 2,    # +2: Excellent improvement
        'Implementation Time': 0,  # 0: Medium time
        'Risk/Complexity': 1  # +1: Low risk
    },
    'Solution 3: All Three': {
        'Cost': -1,          # -1: High cost
        'Performance': 2,    # +2: Best improvement
        'Implementation Time': -1,  # -1: Takes longer
        'Risk/Complexity': 0  # 0: Medium complexity
    },
    'Baseline': {
        'Cost': 0,
        'Performance': 0,
        'Implementation Time': 0,
        'Risk/Complexity': 0
    }
}

# Calculate weighted scores
print(f"\nCriteria Weights:")
for criterion, weight in criteria_weights.items():
    print(f"  {criterion}: {weight*100:.0f}%")

print(f"\n{'Solution':<30} | ", end='')
for criterion in criteria_weights.keys():
    print(f"{criterion:<20} | ", end='')
print("TOTAL SCORE")
print("â”€" * 130)

solution_scores = {}
for solution_name, scores in solutions.items():
    print(f"{solution_name:<30} | ", end='')
    
    total_score = 0
    for criterion in criteria_weights.keys():
        score = scores[criterion]
        weighted = score * criteria_weights[criterion]
        total_score += weighted
        print(f"{score:>+2d} (w:{weighted:+.3f})  | ", end='')
    
    solution_scores[solution_name] = total_score
    print(f"{total_score:+.3f}")

# Ranking
print("\n" + "=" * 60)
print("RANKING")
print("=" * 60)
ranked = sorted(solution_scores.items(), key=lambda x: x[1], reverse=True)
for rank, (solution, score) in enumerate(ranked, 1):
    symbol = "âœ“ RECOMMENDED" if rank == 1 else ""
    print(f"{rank}. {solution:<30} â†’ Score: {score:+.3f} {symbol}")

print(f"\nRECOMMENDATION: {ranked[0][0]}")
print(f"Rationale: Best balance of performance improvement with quick")
print(f"          implementation and low risk/complexity.")
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 6: Improve & DOE
ğŸ“˜ FILE 2 [171] - Quick Reference: DOE Design
ğŸ“˜ FILE 3 [172] - Example (Náº¿u cÃ³)
ğŸ“˜ FILE 5 [174] - FAQ: Design of Experiments
```

---

### PART 9D: Summary Checklist
- [ ] Hiá»ƒu DOE is more efficient than trial-and-error
- [ ] Nháº­n biáº¿t main effects & interaction effects
- [ ] Váº½ Ä‘Æ°á»£c interaction plot
- [ ] Cháº¡y Ä‘Æ°á»£c Pugh Matrix
- [ ] Chá»n Ä‘Æ°á»£c optimal solution dá»±a trÃªn multiple criteria

---

---

## NGÃ€Y 10: SPC - Control Charts & Process Monitoring
### Day 10: I-MR Chart, Control Limits, Sustain

**Duration:** 5-6 hours (FINAL DAY)
**Objective:** Váº½ Control Chart, phÃ¡t hiá»‡n máº¥t kiá»ƒm soÃ¡t, láº­p Control Plan

---

### PART 10A: LÃ½ Thuyáº¿t (2 hours)

#### 1. Statistical Process Control (SPC)

```
Purpose: Monitor process over time to catch changes early

Common Cause Variation:
  = Random, natural variation
  = Within control limits
  = Do nothing (don't over-react)
  
Special Cause Variation:
  = Non-random, assignable cause
  = Outside control limits OR pattern detected
  = INVESTIGATE & FIX
```

#### 2. Control Limits (3-Sigma Rule)

```
UCL (Upper Control Limit) = Î¼ + 3Ïƒ
CL (Center Line) = Î¼
LCL (Lower Control Limit) = Î¼ - 3Ïƒ

Why 3Ïƒ?
  If normal distribution: 99.7% of data within Â±3Ïƒ
  â†’ Only 0.3% chance point falls outside by random chance
  â†’ If we see point outside â†’ Likely special cause!
```

#### 3. I-MR Chart (Individual & Moving Range)

```
Used for: Individual observations (not subgroups)

Chart 1: Individual values (I-chart)
  - Plot each measurement
  - UCL/LCL = Â±3Ïƒ from mean

Chart 2: Moving Range (MR-chart)
  - Plot |x_i - x_{i-1}| (consecutive differences)
  - Detects changes in variation
  - Used to estimate Ïƒ
```

#### 4. Detection Rules (When to Investigate)

**Nelson Rules:**
```
Rule 1: One point beyond 3Ïƒ from center line
Rule 2: Nine points in a row on same side of center line
Rule 3: Six points in a row steadily increasing or decreasing
Rule 4: Fourteen points alternating up and down
Rule 5: Two out of three points beyond 2Ïƒ (same side)
Rule 6: Four out of five beyond 1Ïƒ (same side)
Rule 7: Fifteen points within 1Ïƒ (both sides combined)
Rule 8: Eight points beyond 1Ïƒ (both sides)
```

#### 5. Control Plan (Sustain)

```
Elements:
  1. What: Variable to monitor
  2. How: Measurement method
  3. Frequency: How often check
  4. Control Limits: UCL & LCL
  5. Who: Responsibility
  6. Action: If out of control
```

**Reference:**
```
ğŸ“˜ ASQ BBBOK - CONTROL Phase: SPC & Control Charts
ğŸ“˜ ISCCA Materials - Process Control & Monitoring
ğŸ“˜ FILE 1 [170] - SECTION 6: Control Charts
ğŸ“˜ FILE 2 [171] - SPC Formulas & Nelson Rules
```

---

### PART 10B: NotebookLM Q&A (1.5 hours)

**Prompt:**
```
TÃ´i Ä‘ang monitoring API response time. 
Dá»¯ liá»‡u 30 ngÃ y gáº§n Ä‘Ã¢y:
- Mean = 105ms
- Std Dev = 8ms
- Max spike = 142ms (dá»‹p Prime Day sale)
- Min = 92ms

Há»i:
1. TÃ­nh UCL & LCL (3-sigma)
2. Con sá»‘ 142ms cÃ³ pháº£i "out of control" khÃ´ng?
3. Náº¿u cÃ³ 10 ngÃ y liÃªn tiáº¿p > 120ms â†’ Äiá»u gÃ¬ xáº£y ra?
4. LÃ m Control Plan Ä‘á»ƒ sustain improvement
   - Monitor daily?
   - Alert threshold?
   - Who responsible?
   - Action if > UCL?
```

**Expected Outcome:**
- TÃ­nh Ä‘Æ°á»£c control limits
- PhÃ¡t hiá»‡n special cause
- Láº­p Ä‘Æ°á»£c Control Plan

---

### PART 10C: Python Hands-on (1.5 hours) - FINAL TASK

**Task 1: Create & Analyze Control Chart**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

print("=" * 60)
print("SPC ANALYSIS: API Response Time Monitoring")
print("=" * 60)

# Simulate 30 days of API response time data
np.random.seed(42)
days = np.arange(1, 31)

# Generate baseline data (centered around 105ms)
baseline_data = np.random.normal(loc=105, scale=8, size=30)

# Add special cause event (Day 15-20: High load from sale event)
data = baseline_data.copy()
data[14:20] = np.random.normal(loc=130, scale=10, size=6)

df_spc = pd.DataFrame({
    'Day': days,
    'Response_Time_ms': data
})

print(f"\nData Summary:")
print(f"  Mean: {data.mean():.2f} ms")
print(f"  Std Dev: {data.std():.2f} ms")
print(f"  Min: {data.min():.2f} ms")
print(f"  Max: {data.max():.2f} ms")

# Calculate control limits (assuming normal distribution)
mean = data.mean()
std_dev = data.std()
UCL = mean + 3 * std_dev
LCL = mean - 3 * std_dev

print(f"\nControl Limits (3-Sigma):")
print(f"  Upper Control Limit (UCL): {UCL:.2f} ms")
print(f"  Center Line (CL): {mean:.2f} ms")
print(f"  Lower Control Limit (LCL): {LCL:.2f} ms")

# Identify out-of-control points
out_of_control = df_spc[(df_spc['Response_Time_ms'] > UCL) | 
                         (df_spc['Response_Time_ms'] < LCL)]

print(f"\nOut-of-Control Points (>3Ïƒ):")
if len(out_of_control) == 0:
    print("  None detected")
else:
    print(out_of_control.to_string(index=False))

# Nelson Rule 2: 9 consecutive points on same side
print(f"\nNelson Rule 2 Check (9+ points above/below center):")
above_center = (df_spc['Response_Time_ms'] > mean).values
runs = []
current_run = 1
current_side = above_center[0]

for i in range(1, len(above_center)):
    if above_center[i] == current_side:
        current_run += 1
    else:
        if current_run >= 9:
            runs.append((current_side, current_run, i - current_run))
        current_run = 1
        current_side = above_center[i]

if current_run >= 9:
    runs.append((current_side, current_run, len(above_center) - current_run))

if runs:
    print(f"  âš ï¸ DETECTED!")
    for side, run_length, start_day in runs:
        side_str = "ABOVE" if side else "BELOW"
        print(f"    {run_length} points {side_str} center starting Day {start_day + 1}")
else:
    print(f"  OK: No runs of 9+ consecutive points")

# Plot control chart
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))

# I-Chart
ax1.plot(df_spc['Day'], df_spc['Response_Time_ms'], marker='o', linewidth=2, 
         label='Response Time', color='blue')
ax1.axhline(mean, color='green', linestyle='-', linewidth=2, label=f'CL ({mean:.1f} ms)')
ax1.axhline(UCL, color='red', linestyle='--', linewidth=2, label=f'UCL ({UCL:.1f} ms)')
ax1.axhline(LCL, color='red', linestyle='--', linewidth=2, label=f'LCL ({LCL:.1f} ms)')
ax1.fill_between(df_spc['Day'], LCL, UCL, alpha=0.1, color='green', label='Control Zone')

# Mark out-of-control points
if len(out_of_control) > 0:
    ax1.scatter(out_of_control['Day'], out_of_control['Response_Time_ms'],
               color='red', s=200, marker='X', zorder=5, label='Out of Control')

# Mark special cause period
ax1.axvspan(14.5, 20.5, alpha=0.2, color='orange', label='High-Load Period (Days 15-20)')

ax1.set_ylabel('Response Time (ms)')
ax1.set_title('I-MR Control Chart: API Response Time')
ax1.legend(loc='upper left')
ax1.grid(True, alpha=0.3)
ax1.set_xlim(0.5, 30.5)

# MR-Chart (Moving Range)
mr_values = np.abs(np.diff(df_spc['Response_Time_ms']))
df_mr = pd.DataFrame({
    'Day': df_spc['Day'][1:],
    'Moving_Range': mr_values
})

mr_mean = mr_values.mean()
mr_ucl = mr_mean * 3.267  # Constant for MR chart

ax2.plot(df_mr['Day'], df_mr['Moving_Range'], marker='s', linewidth=2, 
         label='Moving Range', color='purple')
ax2.axhline(mr_mean, color='green', linestyle='-', linewidth=2, label=f'MR Avg ({mr_mean:.2f})')
ax2.axhline(mr_ucl, color='red', linestyle='--', linewidth=2, label=f'UCL ({mr_ucl:.2f})')

ax2.set_xlabel('Day')
ax2.set_ylabel('Range (ms)')
ax2.set_title('Moving Range Chart: Variation Over Time')
ax2.legend()
ax2.grid(True, alpha=0.3)
ax2.set_xlim(0.5, 30.5)

plt.tight_layout()
plt.show()
```

**Task 2: Control Plan Document**

```python
control_plan = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              CONTROL PLAN - SPC MONITORING                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROCESS: API Response Time Monitoring
DATE: {pd.Timestamp.now().strftime('%Y-%m-%d')}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. VARIABLE TO MONITOR (CTQ)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Metric: API Response Time
Unit: milliseconds (ms)
Baseline Mean: {mean:.2f} ms
Target: < 100 ms
Specification: LSL=0, USL=500ms

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2. MEASUREMENT METHOD (HOW)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Measurement System: Application Performance Monitoring (APM) tool
  Tool: DataDog / New Relic / Similar
  Sampling: End-to-end response time (client perspective)
  Frequency: Real-time (every request)
  
Measurement Accuracy: Â±5ms (verified via Gage R&R)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3. MONITORING FREQUENCY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Real-Time Monitoring:
  - Dashboard updated every 1 minute
  - Alert if single measurement > UCL ({UCL:.0f} ms)
  
Daily Review:
  - Calculate daily mean & check against control limits
  - Time: 9 AM daily
  
Weekly Review:
  - Full SPC analysis
  - Time: Every Monday 10 AM
  - Document any trends or shifts

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
4. CONTROL LIMITS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
For I-Chart (Individual values):
  UCL (Upper Control Limit): {UCL:.2f} ms
  CL (Center Line): {mean:.2f} ms
  LCL (Lower Control Limit): {LCL:.2f} ms

For MR-Chart (Moving Range):
  MR Average: {mr_mean:.2f} ms
  MR UCL: {mr_ucl:.2f} ms

Detection Triggers:
  âœ“ One point > UCL or < LCL
  âœ“ 9 consecutive points above/below CL
  âœ“ 6 consecutive points increasing/decreasing
  âœ“ Unusual patterns visible

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5. RESPONSIBILITY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Daily Monitoring: DevOps Engineer (John)
Weekly Review: Engineering Lead (Sarah)
Action on Alert: On-call Engineer (Rotate)
Data Archival: Database Admin (Mike)

Contact:
  Slack: #api-performance
  Escalation: sarah@company.com

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
6. ACTION PLAN (If Out of Control)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Level 1: Single point > UCL (immediate)
  Action:
    - Check monitoring tool (false positive?)
    - Look for external cause (traffic spike, deployment?)
    - If repeats, escalate to Level 2

Level 2: Sustained elevation (3+ consecutive points near/above UCL)
  Action:
    - Review recent code deployments
    - Check infrastructure metrics (CPU, memory, DB)
    - If due to code: Rollback or hotfix
    - If due to infrastructure: Scale up
    - Document root cause

Level 3: Persistent shift (mean > {mean+15:.0f} ms for 3+ days)
  Action:
    - Call incident response meeting
    - Assign task force
    - Implement improvement project (DOE)
    - Target restoration time: 24-48 hours

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
7. DOCUMENTATION & RECORDS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Daily Logs: Excel file shared drive
  Path: /ProjectSharedDrive/API_Performance/Daily_SPC.xlsx
  Columns: Date, Mean, Std Dev, Max, Events

Incident Reports:
  Database: Jira (tag: API-SPC-XXX)
  Required: Date, Impact, Root Cause, Action Taken, Result

Control Chart Archive:
  Monthly graphs saved to:
  /ProjectSharedDrive/API_Performance/2024/SPC_Charts/

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
8. SUSTAINED IMPROVEMENT ACTIONS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
To prevent regression:

âœ“ Weekly team standup on SPC results (5 min)
âœ“ Monthly review with stakeholders
âœ“ Training for new team members on SPC interpretation
âœ“ Quarterly recalibration of control limits
âœ“ Benchmark against competitor performance

Red Flag Indicators:
  - Control limits breached > 2x per month
  - Increasing UCL trend (variation growing)
  - Frequent special cause events
  â†’ All trigger process improvement project

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
9. APPROVAL & REVIEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Created by: Six Sigma Team
Approved by: Engineering Director
Review date: {(pd.Timestamp.now() + pd.DateOffset(months=3)).strftime('%Y-%m-%d')}
Next review: Quarterly (or sooner if changes)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

print(control_plan)

# Save to file
with open('control_plan.txt', 'w') as f:
    f.write(control_plan)

print("Control Plan saved to 'control_plan.txt'")
```

**Task 3: Final Summary Report**

```python
summary_report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        10-DAY SIX SIGMA LEARNING - COMPLETION SUMMARY        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Date Range: Days 1-10
Overall Status: âœ“ COMPLETE

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PHASE 1: DEFINE & LEAN (Days 1-3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Day 1: Six Sigma Overview, DMAIC, 8 Wastes
  â†’ Understand methodology, identify waste sources

âœ“ Day 2: Lean Tools, Descriptive Statistics
  â†’ 5S, Kaizen, Poka-Yoke mastered
  â†’ Basic statistics calculated & visualized

âœ“ Day 3: Project Charter, VOC â†’ CTQ, SIPOC
  â†’ Project clearly defined & scoped
  â†’ Customer requirements translated to metrics

Status: READY TO MEASURE âœ“

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PHASE 2: MEASURE (Days 4-6)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Day 4: Data Collection Plan, Sampling Strategies
  â†’ Sampling methods understood
  â†’ Data collection plan documented

âœ“ Day 5: Gage R&R Analysis (CRITICAL)
  â†’ MSA completed, measurement system validated
  â†’ Gage R&R < 30%: System adequate âœ“

âœ“ Day 6: Process Capability (Cpk/Ppk)
  â†’ Current state quantified
  â†’ Process baseline established
  â†’ Improvement targets identified

Status: BASELINE ESTABLISHED, READY TO ANALYZE âœ“

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PHASE 3: ANALYZE (Days 7-8)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Day 7: Hypothesis Testing (t-test, ANOVA)
  â†’ Statistical tests mastered
  â†’ P-value interpretation clear
  â†’ Differences between groups identified

âœ“ Day 8: Correlation, Regression, Root Cause
  â†’ X factors linked to Y output
  â†’ Fishbone & 5 Whys applied
  â†’ Root causes identified
  â†’ Priority factors for improvement known

Status: ROOT CAUSE IDENTIFIED, READY TO IMPROVE âœ“

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PHASE 4: IMPROVE & CONTROL (Days 9-10)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Day 9: Design of Experiments (DOE)
  â†’ Factorial designs understood
  â†’ Interaction effects identified
  â†’ Optimal solution selected (Pugh Matrix)
  â†’ Implementation ready

âœ“ Day 10: Statistical Process Control (SPC)
  â†’ Control charts created & analyzed
  â†’ Out-of-control detection mastered
  â†’ Control Plan documented
  â†’ Sustain strategy in place

Status: IMPROVEMENT READY, SUSTAIN PLAN IN PLACE âœ“

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

KEY METRICS ACHIEVED
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Before (Baseline):
  â€¢ Defect Rate: ~5-8%
  â€¢ Process Capability: Cpk < 1.33 (Not capable)
  â€¢ Variation: High

After (Target):
  â€¢ Defect Rate: < 2%
  â€¢ Process Capability: Cpk â‰¥ 1.33 (Capable)
  â€¢ Variation: Controlled & stable

Estimated Timeline: 30-60 days for full implementation

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TECHNICAL SKILLS MASTERED
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Python & Data Analysis:
  âœ“ Pandas: Data loading, cleaning, transformation
  âœ“ NumPy: Statistical calculations
  âœ“ SciPy: Hypothesis testing (t-test, ANOVA, etc.)
  âœ“ Matplotlib/Seaborn: Data visualization
  âœ“ Scikit-learn: Regression modeling

Six Sigma Methods:
  âœ“ DMAIC methodology
  âœ“ Project Charter writing
  âœ“ VOC â†’ CTQ translation
  âœ“ Data collection planning
  âœ“ Gage R&R analysis
  âœ“ Capability analysis (Cpk/Ppk)
  âœ“ Hypothesis testing
  âœ“ Root cause analysis (Fishbone, 5 Whys)
  âœ“ Design of Experiments (DOE)
  âœ“ Control charting (SPC)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

NEXT STEPS - BEYOND 10 DAYS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Week 2-4: Implementation Phase
  â€¢ Execute improvement actions from DOE
  â€¢ Verify expected benefit realization
  â€¢ Make process adjustments as needed
  â€¢ Conduct interim capability analysis

Week 5+: Sustain Phase
  â€¢ Daily SPC monitoring
  â€¢ Weekly team reviews
  â€¢ Document lessons learned
  â€¢ Replicate success to other processes
  â€¢ Prepare Green Belt certification exam (if pursuing)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RESOURCES COMPILED
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Bilingual Files Created:
  âœ“ FILE 1: Complete Guide (170) - Theory & Hands-on
  âœ“ FILE 2: Quick Reference (171) - Formulas & Commands
  âœ“ FILE 3: Examples (172) - Copy-paste code
  âœ“ FILE 4: Index (173) - Learning roadmap
  âœ“ FILE 5: FAQ (174) - Troubleshooting & Q&A

External References:
  âœ“ ASQ BBBOK (Black Belt Body of Knowledge)
  âœ“ ISCCA Six Sigma Training Materials
  âœ“ Python libraries: pandas, NumPy, SciPy, matplotlib

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CERTIFICATION & RECOGNITION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
This 10-day intensive covers:
  âœ“ Green Belt Level: Theory + Hands-on (80% complete)
  âœ“ Black Belt Level: Preparation (40% complete)

To achieve Green Belt:
  â†’ Pass ASQ Green Belt exam (~4 additional weeks study)
  â†’ Complete 1-2 real projects with documented results

To achieve Black Belt:
  â†’ Pass ASQ Black Belt exam
  â†’ Demonstrate 2-3 projects with > $100k impact each
  â†’ Mentor Green Belts

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FINAL NOTES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"From Zero to Six Sigma in 10 Days"

You've learned:
  1. The MINDSET: Data-driven, systematic improvement
  2. The TOOLS: DMAIC, DOE, SPC, and Python automation
  3. The PRACTICE: Real analysis with code & visualization

Success requires:
  âœ“ Daily practice (at least 30 min with code)
  âœ“ Apply to real problems (best learning method)
  âœ“ Document & share learnings (teach others)
  âœ“ Join Six Sigma community (ASQ, local meetups)

Your competitive advantage:
  â†’ Unlike typical Six Sigma training (pure theory)
  â†’ You have Python skills to automate analysis
  â†’ You can tackle BIG DATA (millions of records)
  â†’ You're 10x more efficient than spreadsheet users

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Generated: {pd.Timestamp.now()}
Status: READY FOR REAL-WORLD APPLICATION âœ“âœ“âœ“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

print(summary_report)

with open('six_sigma_completion_summary.txt', 'w') as f:
    f.write(summary_report)

print("\nCompletion Summary saved!")
```

**File References:**
```
ğŸ“˜ FILE 1 [170] - SECTION 6: Control Phase
ğŸ“˜ FILE 2 [171] - Quick Reference: SPC Formulas
ğŸ“˜ FILE 3 [172] - Example 4: Control Chart
ğŸ“˜ FILE 5 [174] - FAQ: Interpreting Control Charts
ğŸ“˜ ASQ BBBOK - CONTROL Phase
ğŸ“˜ ISCCA Materials - Process Control
```

---

### PART 10D: Summary Checklist â­ FINAL
- [ ] TÃ­nh Ä‘Æ°á»£c control limits (3-sigma)
- [ ] Váº½ Ä‘Æ°á»£c I-MR control chart
- [ ] PhÃ¡t hiá»‡n Ä‘Æ°á»£c out-of-control points
- [ ] Ãp dá»¥ng Nelson Rules (9-point rule, trend rule)
- [ ] Láº­p Ä‘Æ°á»£c Control Plan chi tiáº¿t
- [ ] Hiá»ƒu Common Cause vs Special Cause
- [ ] Biáº¿t cÃ¡ch sustain improvement

---

---

# Tá»”NG Káº¾T 10 NGÃ€Y

## COMPLETION CHECKLIST

### GIAI ÄOáº N 1: DEFINE & LEAN (Days 1-3)
- [ ] Six Sigma methodology (DMAIC) fully understood
- [ ] 8 Wastes (DOWNTIME) memorized & applicable
- [ ] Lean tools (5S, Kaizen, Poka-Yoke) mastered
- [ ] Descriptive statistics (mean, median, std dev) calculated
- [ ] Histogram created with distribution overlay
- [ ] Project Charter written (Business Case + Problem + Goal)
- [ ] VOC translated to CTQ with metrics
- [ ] SIPOC diagram created & saved

### GIAI ÄOáº N 2: MEASURE (Days 4-6)
- [ ] Data Collection Plan documented
- [ ] Sampling methods understood & applied (Random, Stratified)
- [ ] **Gage R&R analysis completed** â­ CRITICAL
- [ ] Gage R&R % calculated & acceptable (< 30%)
- [ ] Process Capability (Cpk) calculated
- [ ] Cpk interpreted correctly (benchmark: 1.33)
- [ ] Capability improvement plan created
- [ ] Baseline metrics established & documented

### GIAI ÄOáº N 3: ANALYZE (Days 7-8)
- [ ] Normality test (Shapiro-Wilk) performed
- [ ] t-test or ANOVA executed on real data
- [ ] P-value < 0.05 correctly interpreted
- [ ] Correlation coefficient calculated
- [ ] Linear regression model built & RÂ² interpreted
- [ ] Scatter plot with regression line visualized
- [ ] Fishbone diagram created with 5+ causes
- [ ] 5 Whys technique applied to root cause
- [ ] Vital few X factors identified (Pareto principle)

### GIAI ÄOáº N 4: IMPROVE & CONTROL (Days 9-10)
- [ ] 2Â³ Factorial Design OR appropriate DOE executed
- [ ] Main effects plot created & interpreted
- [ ] Interaction effects identified
- [ ] Pugh Matrix completed for solution selection
- [ ] Optimal configuration chosen with justification
- [ ] I-MR Control Chart created
- [ ] Control limits (UCL, CL, LCL) calculated
- [ ] Out-of-control points detected & marked
- [ ] Nelson Rules applied (9-point rule, trend rule)
- [ ] Control Plan document completed
- [ ] Sustain strategy defined

---

## TECHNICAL SKILLS VERIFIED

### Python Skills
- [âœ“] Pandas: df.read_csv(), describe(), groupby(), dropna(), etc.
- [âœ“] NumPy: mean(), std(), array operations, random.normal()
- [âœ“] SciPy: stats.shapiro(), ttest_ind(), f_oneway(), pearsonr()
- [âœ“] Matplotlib: plot(), scatter(), hist(), axhline(), bar()
- [âœ“] Scikit-learn: LinearRegression, fit(), predict()

### Six Sigma Skills
- [âœ“] DMAIC methodology understanding (80%+)
- [âœ“] Project management (charter, scope, goals)
- [âœ“] Statistical analysis (capability, hypothesis testing)
- [âœ“] Root cause analysis (fishbone, 5 whys)
- [âœ“] Experimental design (DOE, factorial)
- [âœ“] Process control (SPC, control charts)

### Business Skills
- [âœ“] Translating customer voice to metrics
- [âœ“] Data-driven decision making
- [âœ“] Communicating with executives (business case)
- [âœ“] Selecting solutions using weighted criteria
- [âœ“] Writing control plans for sustainability

---

## REFERENCES USED

**Primary Sources:**
```
ğŸ“˜ ASQ Black Belt Body of Knowledge (BBBOK)
   - Introduction to Six Sigma
   - DMAIC phases in detail
   - Statistical tests & formulas
   - Reference: https://www.asq.org/

ğŸ“˜ ISCCA Six Sigma Training Materials
   - Lean principles & tools
   - Hypothesis testing
   - Design of Experiments
   - Reference: ISCCA official curriculum

ğŸ“˜ Python for Six Sigma Files (Created)
   - FILE 1 [170]: Complete Guide
   - FILE 2 [171]: Quick Reference
   - FILE 3 [172]: Examples
   - FILE 4 [173]: Learning Roadmap
   - FILE 5 [174]: FAQ & Troubleshooting
```

**Secondary Sources:**
```
ğŸ“š Statistics Textbooks
  - Normality testing (Shapiro-Wilk)
  - Hypothesis testing (p-value interpretation)
  - Regression analysis (RÂ², slope, intercept)

ğŸ“š Six Sigma Publications
  - Motorola Six Sigma history
  - DPMO to Sigma conversion table
  - Control chart rules (Nelson Rules)

ğŸ“š Python Documentation
  - SciPy.stats: All statistical tests
  - Pandas: Data manipulation
  - Matplotlib: Visualization
```

---

## SUCCESS CRITERIA MET?

| Criterion | Status | Evidence |
|-----------|--------|----------|
| DMAIC methodology understood | âœ“ | Can explain each phase |
| Data analysis skills (Python) | âœ“ | Can run all tests & visualizations |
| Statistical tests mastered | âœ“ | Cp/Cpk, t-test, ANOVA all covered |
| Root cause analysis completed | âœ“ | Fishbone, 5 Whys, Pareto applied |
| Control plan created | âœ“ | SPC, control limits, action plan |
| Project charter written | âœ“ | Business case + problem + goal |
| Ready for Green Belt exam | â‰ˆ 70% | Need 4 more weeks for certification |
| Ready for real project | âœ“ | All tools & skills learned |

---

## FINAL WORDS

**Congratulations!** You've completed a comprehensive 10-day Six Sigma intensive.

You now have:
1. âœ“ Theoretical understanding of DMAIC
2. âœ“ Practical Python skills for automation
3. âœ“ Real-world examples & templates
4. âœ“ A complete toolkit for your next project

**Next: Pick a real problem â†’ Apply DMAIC â†’ Achieve results â†’ Get certified**

Good luck! ğŸš€

---

Generated: {pd.Timestamp.now()}
